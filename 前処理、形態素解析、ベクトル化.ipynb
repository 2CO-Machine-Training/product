{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"前処理、形態素解析、ベクトル化.ipynb","provenance":[],"collapsed_sections":["37aVJcMQ20LI","5ezGBGVPyl7i","L1Fv87VEA6z_","FK6Eozu1OxGo","09Xl8ciUX4gI","FyrCW8QySJ0C","EcFlsEiNYnRM","7fBNaAVyb2iD","dFX_5ubQBT-T","wSaPaVo6KfkV","cl1MghTaoS5u"],"toc_visible":true,"authorship_tag":"ABX9TyPgXqRMtg9ksL8PzRjClcmw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yNJulcrxM2Kd"},"source":["# 前処理、形態素解析、ベクトル化\n","\n","処理の流れ\n","\n","生文 → 形態素解析 → 数値化（ベクトル化）\n","\n","独立請求項の生文が入力されている列の1行目に「独立請求項」という名前がつけられているexcelデータを \n","\n","'sample_data.xlsx' として 'data/'フォルダに保存しておけばサンプルプログラムが動作します。"]},{"cell_type":"code","metadata":{"id":"OBJpPJMUTSW2","executionInfo":{"status":"ok","timestamp":1603066272158,"user_tz":-540,"elapsed":23250,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"192e796b-a8d9-48b6-f659-37e0f1f24678","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import os\n","from google.colab import drive\n","\n","# googleドライブのマウント \n","drive.mount('/content/drive/')\n","\n","# 作業ファイルをマイドライブに変更\n","os.chdir('/content/drive/My Drive/') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jyE1Y_o71N9Z","executionInfo":{"status":"ok","timestamp":1603067148121,"user_tz":-540,"elapsed":58069,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"c3b10405-52c0-490e-8a6e-ed0500785e88","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# pandasモジュールを用いたサンプルデータの読み込み\n","\n","import pandas as pd\n","\n","data = pd.read_excel('data/original_data.xlsm', sheet_name= 'text')\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>公報番号(全文リンク)</th>\n","      <th>発明等の名称</th>\n","      <th>出願人・権利者(最新)</th>\n","      <th>ＩＰＣ(最新)</th>\n","      <th>ＦＩ(最新)</th>\n","      <th>Ｆターム(最新)</th>\n","      <th>請求の範囲(独立請求項)</th>\n","      <th>ＩＰＣ(最新,筆頭)</th>\n","      <th>FI(最新)</th>\n","      <th>FI(整理)</th>\n","      <th>ラベル</th>\n","      <th>正誤</th>\n","      <th>FI(整理,重複削除)</th>\n","      <th>錯誤</th>\n","      <th>データ数</th>\n","      <th>錯誤率</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>特開2019-220570</td>\n","      <td>パターン形成方法、パターン形成物およびパターン形成装置</td>\n","      <td>コニカミノルタ株式会社</td>\n","      <td>H05K3/10;C09D11/30;B41M5/00;B41J2/01;B05D1/36;...</td>\n","      <td>H05K  3/10        D;B41J  2/01    501;B41J  2/...</td>\n","      <td>2C056 FD10;2C056 FD01;2C056 FB05;2C056 EC72;2C...</td>\n","      <td>【請求項１】  第１の液体を基材表面に付与されてなる第１液層を形成する工程と、  前記第１液...</td>\n","      <td>H05K3/10</td>\n","      <td>H05K3/10D</td>\n","      <td>H05K3/10</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>B41M5/001</td>\n","      <td>83.0</td>\n","      <td>241.0</td>\n","      <td>0.344398</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>特開2019-219949</td>\n","      <td>導電性細線パターンの製造方法及びタッチパネルセンサーの製造方法</td>\n","      <td>コニカミノルタ株式会社</td>\n","      <td>G06F3/041;G06F3/044;H05K3/10;H05K3/24</td>\n","      <td>G06F  3/041   660;G06F  3/044   127;G06F  3/04...</td>\n","      <td>5E343 AA12;5E343 GG20;5E343 AA18;5E343 BB23;5E...</td>\n","      <td>【請求項１】  ２種以上の金属によって構成される導電性細線によって構成される、１０００ｃｍ２...</td>\n","      <td>G06F3/041</td>\n","      <td>G06F3/041660</td>\n","      <td>G06F3/04</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>B41M5/00A</td>\n","      <td>69.0</td>\n","      <td>166.0</td>\n","      <td>0.415663</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>特開2019-218636</td>\n","      <td>染色物の製造方法、染色調整インクジェットインク、及び染色調整インクジェットインクセット</td>\n","      <td>株式会社ミマキエンジニアリング</td>\n","      <td>D06P5/00;C09D11/54;C09D11/32;C09D11/40;D06P5/3...</td>\n","      <td>D06P  5/00    120 Z;B41J  2/01    501;B41M  5/...</td>\n","      <td>2C056 FC01;2C056 HA42;2C056 EA04;2C056 FB03;2H...</td>\n","      <td>【請求項１】  染色液によるメディアへの着色度合を調整する単独では前記メディア上で視認困難な...</td>\n","      <td>D06P5/00</td>\n","      <td>D06P5/00120Z</td>\n","      <td>D06P5/00</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>C09D11/3</td>\n","      <td>60.0</td>\n","      <td>1122.0</td>\n","      <td>0.053476</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>特開2019-218522</td>\n","      <td>インクジェットインク</td>\n","      <td>ゼネラル株式会社</td>\n","      <td>C09D11/30;C09D11/38;B41J2/01;B41M5/00;A61K9/20...</td>\n","      <td>C09D 11/30;B41J  2/01    501;B41M  5/00    120...</td>\n","      <td>2C056 FC01;2H186 BA08;2H186 DA12;2H186 FB11;2H...</td>\n","      <td>【請求項１】  着色剤、アラビアガム、炭素数１２以上、２０以下の高級アルコール、炭素数１以上...</td>\n","      <td>C09D11/30</td>\n","      <td>C09D11/30</td>\n","      <td>C09D11/3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>B41J2/01</td>\n","      <td>58.0</td>\n","      <td>1109.0</td>\n","      <td>0.052299</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>特開2019-218514</td>\n","      <td>インクジェット記録液セット、インクジェット記録用前処理液の製造方法、印刷物及びインクジェット...</td>\n","      <td>コニカミノルタ株式会社</td>\n","      <td>C09D11/54;C09D11/322;B41J2/01;B41M5/00</td>\n","      <td>C09D 11/54;B41J  2/01    123;B41J  2/01    501...</td>\n","      <td>2C056 FC01;2C056 FB02;2C056 EA13;2C056 EA04;2C...</td>\n","      <td>【請求項１】  少なくとも前処理液とインクとからなるインクジェット記録液セットであって、  ...</td>\n","      <td>C09D11/54</td>\n","      <td>C09D11/54</td>\n","      <td>C09D11/5</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>D06P5/00</td>\n","      <td>25.0</td>\n","      <td>44.0</td>\n","      <td>0.568182</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     公報番号(全文リンク)  ...       錯誤率\n","0  特開2019-220570  ...  0.344398\n","1  特開2019-219949  ...  0.415663\n","2  特開2019-218636  ...  0.053476\n","3  特開2019-218522  ...  0.052299\n","4  特開2019-218514  ...  0.568182\n","\n","[5 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"37aVJcMQ20LI"},"source":["# 前処理\n","\n","[正規表現](https://docs.python.org/ja/3/howto/regex.html)を使い、特許文書に特有の文字列を削除します。\n","\n","処理した文字列をリスト（processed_data）に収納します。\n","\n","processed_dataをnumpy形式に変換し、保存します。\n","\n","また、先頭から10文書を表示します。"]},{"cell_type":"code","metadata":{"id":"v5s7-Nrl3QB4","executionInfo":{"status":"ok","timestamp":1602905082961,"user_tz":-540,"elapsed":670,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"3a7d339e-e4e5-49cc-b3bb-e928ec544600","colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["import re\n","import numpy as np\n","import pandas as pd\n","\n","#  正規表現のコンパイル\n","sep = re.compile('【.*?】|\\n|\\u3000| |\\n') \n","\n","processed_data = []\n","for text in data['請求の範囲(独立請求項)']:\n","  processed_data.append(sep.sub('', text))\n","processed_data = np.array(processed_data)\n","np.save('data/processed_data.npy', processed_data)\n","processed_data[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['第１の液体を基材表面に付与されてなる第１液層を形成する工程と、前記第１液層が形成された前記基材表面に、前記第１の液体とは非相溶であり、かつ、前記第１の液体よりも比重が大きい第２の液体の液滴をインクジェット法で付与する工程と、前記第１の液体および第２の液体の一方の液体を選択的に硬化させる工程と、を有する、パターン形成方法。インクジェット法により基材表面に付与された液体が硬化して形成されたパターン形成物であって、前記液体の硬化物により形成されるパターンが有する前記基材表面に接する壁面と、前記基材表面と、の間の角度は、４５°以上である、パターン形成物。第１の液体を基材表面に付与する第１液体付与部と、前記第１の液体が付与された前記基材表面に、前記第１の液体とは非相溶であり、かつ、前記第１の液体よりも比重が大きい第２の液体の液滴をインクジェット法で付与する第２液体付与部と、前記第１の液体および第２の液体の一方の液体を選択的に硬化させる選択的硬化部と、を有する、パターン形成装置。',\n","       '２種以上の金属によって構成される導電性細線によって構成される、１０００ｃｍ２以上の面積にわたる導電性細線パターンの製造方法であって、基材上に第１の金属によって構成された第１の導電性細線をパターニングし、次いで、前記第１の導電性細線に、前記第１の金属とは異なる金属種である第２の金属によって構成された導電性皮膜を被覆する被覆処理を施して、前記第１の導電性細線と前記導電性皮膜とによって構成された第２の導電性細線を形成し、次いで、前記第２の導電性細線に、該第２の導電性細線の線幅の減少速度が０．５μｍ／ｍｉｎ以下となるエッチングを施して、前記第２の導電性細線を構成する前記導電性皮膜の一部が除去された第３の導電性細線を形成することを特徴とする導電性細線パターンの製造方法。',\n","       '染色液によるメディアへの着色度合を調整する単独では前記メディア上で視認困難な染色調整剤と、色材とを含有する染色調整インクを前記メディアにインクジェット方式により塗布する塗布工程と、前記染色調整インクが塗布された前記メディアを前記染色液に浸漬して染色する染色工程と、を備える、染色物の製造方法。染色液によるメディアへの着色度合を調整する単独では前記メディア上で視認困難な染色調整剤と、前記染色液による染色工程で視認できなくなるまで除去される色材と、を含有する染色調整インクジェットインク。染色液によるメディアへの着色度合を調整する単独では前記メディア上で視認困難な染色調整剤と、前記染色液による染色工程で視認可能な程度に残存する色材と、を含有する染色調整インクジェットインク。染色液によるメディアへの着色度合を調整する単独では前記メディア上で視認困難な染色調整剤と、前記染色液による染色工程で視認可能な程度に残存する第１の色材と、を含有する第１の染色調整インクジェットインクと、前記染色調整剤と、前記染...',\n","       '着色剤、アラビアガム、炭素数１２以上、２０以下の高級アルコール、炭素数１以上、４以下の低級アルコール、および水を含むインクジェットインク。',\n","       '少なくとも前処理液とインクとからなるインクジェット記録液セットであって、前記前処理液が、少なくとも、ポリエステル、ポリオレフィン又はポリウレタンの骨格のいずれかを含む水不溶性樹脂微粒子と凝集剤と水とを含有し、前記インクが、少なくとも、顔料とオキサゾリン基を有する化合物と水とを含有する、ことを特徴とするインクジェット記録液セット。',\n","       'インクジェット用の水性インクの製造方法であって、顔料、及び界面活性剤を混合して混合物を得る工程と、得られた前記混合物、及びその他のインク成分を混合する工程と、を有し、前記顔料が、顔料の粒子表面に、（ｉ）アニオン性基、及び、（ｉｉ）他の原子団とアニオン性基とが結合した基、からなる群より選択される官能基が結合した自己分散顔料であるとともに、前記官能基の密度が、０．１０μｍｏｌ／ｍ2以上０．４８μｍｏｌ／ｍ2以下であり、前記界面活性剤が、陽イオンとなりうる窒素原子が第２級アミン又は第３級アミンの構造を有するアミノ酸型界面活性剤であることを特徴とする水性インクの製造方法。',\n","       '水性媒体と、スクアリリウム骨格を有する化合物と樹脂とを含有する赤外線吸収性粒子と、ジアルキルスルホコハク酸塩と、赤色アゾ顔料と、を含む水性インク。水性媒体と、スクアリリウム骨格を有する化合物と樹脂とを含有する赤外線吸収性粒子と、ジアルキルスルホコハク酸塩と、赤色顔料と、を含み、６０℃の環境下で１４日間経過することによる前記赤外線吸収性粒子における赤外線吸光係数の低下率が５％以下である水性インク。',\n","       '平均粒子径が０．４～２．５μｍであり、屈折率が１．４～１．７であり、比重が２．１以下である粒子を含む、インクジェットインク。',\n","       '発光性ナノ結晶粒子を含有する少なくとも１種の発光性インク組成物と、光散乱性粒子を含有する非発光性インク組成物と、を含む、インク組成物セット。発光性ナノ結晶粒子を含有する少なくとも１種の発光性画素部と、光散乱性粒子を含有する非発光性画素部と、を備える、光変換層。',\n","       '少なくともインクジェットインクと前処理液を含むインクジェット記録液セットであって、前記インクジェットインクが、少なくとも顔料、顔料分散剤、水溶性有機溶媒及び水不溶性樹脂を含有し、当該水不溶性樹脂が、ポリエステル骨格、ポリオレフィン骨格又はポリウレタン骨格のいずれかを含む水不溶性樹脂であり、前記前処理液が、少なくとも凝集剤及び水不溶性樹脂微粒子を含有し、当該水不溶性樹脂微粒子が、ポリオレフィン系樹脂がポリウレタン系樹脂に含有された複合樹脂粒子であることを特徴とするインクジェット記録液セット。'],\n","      dtype='<U495')"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"09nHsFrHUBLH"},"source":["# 形態素解析\n","\n","文字列を分解し、スペースで区切った新たな文字列を生成します。"]},{"cell_type":"markdown","metadata":{"id":"5ezGBGVPyl7i"},"source":["## MeCab\n","\n","日本語の文法に依存した形態素解析器として最も有名な方法です。\n","\n","MeCabの導入は環境に依存します。\n","\n","[mecab-python3](https://pypi.org/project/mecab-python3/) （[Python3からMeCabを使う](https://qiita.com/taroc/items/b9afd914432da08dafc8)）\n","\n","[natto-py](https://pypi.org/project/natto-py/)（[Python の MeCab バインディング natto-py を使う](https://qiita.com/buruzaemon/items/975027cea6371b2c5ec3)）\n","\n","等を検索して導入してください。"]},{"cell_type":"code","metadata":{"id":"eEQVWkAfxz1d","executionInfo":{"status":"ok","timestamp":1602905154491,"user_tz":-540,"elapsed":64239,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"4fb25d0c-a419-4973-f4f6-f9068946b684","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# MeCabのインストール\n","!apt install aptitude swig\n","!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n","!pip install mecab-python3\n","!pip install unidic-lite"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  aptitude-common libcgi-fast-perl libcgi-pm-perl libclass-accessor-perl\n","  libcwidget3v5 libencode-locale-perl libfcgi-perl libhtml-parser-perl\n","  libhtml-tagset-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n","  libio-string-perl liblwp-mediatypes-perl libparse-debianchangelog-perl\n","  libsigc++-2.0-0v5 libsub-name-perl libtimedate-perl liburi-perl libxapian30\n","  swig3.0\n","Suggested packages:\n","  aptitude-doc-en | aptitude-doc apt-xapian-index debtags tasksel\n","  libcwidget-dev libdata-dump-perl libhtml-template-perl libxml-simple-perl\n","  libwww-perl xapian-tools swig-doc swig-examples swig3.0-examples swig3.0-doc\n","The following NEW packages will be installed:\n","  aptitude aptitude-common libcgi-fast-perl libcgi-pm-perl\n","  libclass-accessor-perl libcwidget3v5 libencode-locale-perl libfcgi-perl\n","  libhtml-parser-perl libhtml-tagset-perl libhttp-date-perl\n","  libhttp-message-perl libio-html-perl libio-string-perl\n","  liblwp-mediatypes-perl libparse-debianchangelog-perl libsigc++-2.0-0v5\n","  libsub-name-perl libtimedate-perl liburi-perl libxapian30 swig swig3.0\n","0 upgraded, 23 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 4,978 kB of archives.\n","After this operation, 21.4 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude-common all 0.8.10-6ubuntu1 [1,014 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigc++-2.0-0v5 amd64 2.10.0-2 [10.9 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcwidget3v5 amd64 0.5.17-7 [286 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxapian30 amd64 1.4.5-1ubuntu0.1 [631 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 aptitude amd64 0.8.10-6ubuntu1 [1,269 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-tagset-perl all 3.20-3 [12.1 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 liburi-perl all 1.73-1 [77.2 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhtml-parser-perl amd64 3.72-3build1 [85.9 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-pm-perl all 4.38-1 [185 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfcgi-perl amd64 0.78-2build1 [32.8 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcgi-fast-perl all 1:2.13-1 [9,940 B]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsub-name-perl amd64 0.21-1build1 [11.6 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libclass-accessor-perl all 0.51-1 [21.2 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libencode-locale-perl all 1.05-1 [12.3 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-date-perl all 6.02-1 [10.4 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-html-perl all 1.001-1 [14.9 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblwp-mediatypes-perl all 6.02-1 [21.7 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 libhttp-message-perl all 6.14-1 [72.1 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libio-string-perl all 1.08-3 [11.1 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 libparse-debianchangelog-perl all 1.2.0-12 [49.5 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n","Fetched 4,978 kB in 2s (2,674 kB/s)\n","Selecting previously unselected package aptitude-common.\n","(Reading database ... 144611 files and directories currently installed.)\n","Preparing to unpack .../00-aptitude-common_0.8.10-6ubuntu1_all.deb ...\n","Unpacking aptitude-common (0.8.10-6ubuntu1) ...\n","Selecting previously unselected package libsigc++-2.0-0v5:amd64.\n","Preparing to unpack .../01-libsigc++-2.0-0v5_2.10.0-2_amd64.deb ...\n","Unpacking libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n","Selecting previously unselected package libcwidget3v5:amd64.\n","Preparing to unpack .../02-libcwidget3v5_0.5.17-7_amd64.deb ...\n","Unpacking libcwidget3v5:amd64 (0.5.17-7) ...\n","Selecting previously unselected package libxapian30:amd64.\n","Preparing to unpack .../03-libxapian30_1.4.5-1ubuntu0.1_amd64.deb ...\n","Unpacking libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n","Selecting previously unselected package aptitude.\n","Preparing to unpack .../04-aptitude_0.8.10-6ubuntu1_amd64.deb ...\n","Unpacking aptitude (0.8.10-6ubuntu1) ...\n","Selecting previously unselected package libhtml-tagset-perl.\n","Preparing to unpack .../05-libhtml-tagset-perl_3.20-3_all.deb ...\n","Unpacking libhtml-tagset-perl (3.20-3) ...\n","Selecting previously unselected package liburi-perl.\n","Preparing to unpack .../06-liburi-perl_1.73-1_all.deb ...\n","Unpacking liburi-perl (1.73-1) ...\n","Selecting previously unselected package libhtml-parser-perl.\n","Preparing to unpack .../07-libhtml-parser-perl_3.72-3build1_amd64.deb ...\n","Unpacking libhtml-parser-perl (3.72-3build1) ...\n","Selecting previously unselected package libcgi-pm-perl.\n","Preparing to unpack .../08-libcgi-pm-perl_4.38-1_all.deb ...\n","Unpacking libcgi-pm-perl (4.38-1) ...\n","Selecting previously unselected package libfcgi-perl.\n","Preparing to unpack .../09-libfcgi-perl_0.78-2build1_amd64.deb ...\n","Unpacking libfcgi-perl (0.78-2build1) ...\n","Selecting previously unselected package libcgi-fast-perl.\n","Preparing to unpack .../10-libcgi-fast-perl_1%3a2.13-1_all.deb ...\n","Unpacking libcgi-fast-perl (1:2.13-1) ...\n","Selecting previously unselected package libsub-name-perl.\n","Preparing to unpack .../11-libsub-name-perl_0.21-1build1_amd64.deb ...\n","Unpacking libsub-name-perl (0.21-1build1) ...\n","Selecting previously unselected package libclass-accessor-perl.\n","Preparing to unpack .../12-libclass-accessor-perl_0.51-1_all.deb ...\n","Unpacking libclass-accessor-perl (0.51-1) ...\n","Selecting previously unselected package libencode-locale-perl.\n","Preparing to unpack .../13-libencode-locale-perl_1.05-1_all.deb ...\n","Unpacking libencode-locale-perl (1.05-1) ...\n","Selecting previously unselected package libtimedate-perl.\n","Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n","Unpacking libtimedate-perl (2.3000-2) ...\n","Selecting previously unselected package libhttp-date-perl.\n","Preparing to unpack .../15-libhttp-date-perl_6.02-1_all.deb ...\n","Unpacking libhttp-date-perl (6.02-1) ...\n","Selecting previously unselected package libio-html-perl.\n","Preparing to unpack .../16-libio-html-perl_1.001-1_all.deb ...\n","Unpacking libio-html-perl (1.001-1) ...\n","Selecting previously unselected package liblwp-mediatypes-perl.\n","Preparing to unpack .../17-liblwp-mediatypes-perl_6.02-1_all.deb ...\n","Unpacking liblwp-mediatypes-perl (6.02-1) ...\n","Selecting previously unselected package libhttp-message-perl.\n","Preparing to unpack .../18-libhttp-message-perl_6.14-1_all.deb ...\n","Unpacking libhttp-message-perl (6.14-1) ...\n","Selecting previously unselected package libio-string-perl.\n","Preparing to unpack .../19-libio-string-perl_1.08-3_all.deb ...\n","Unpacking libio-string-perl (1.08-3) ...\n","Selecting previously unselected package libparse-debianchangelog-perl.\n","Preparing to unpack .../20-libparse-debianchangelog-perl_1.2.0-12_all.deb ...\n","Unpacking libparse-debianchangelog-perl (1.2.0-12) ...\n","Selecting previously unselected package swig3.0.\n","Preparing to unpack .../21-swig3.0_3.0.12-1_amd64.deb ...\n","Unpacking swig3.0 (3.0.12-1) ...\n","Selecting previously unselected package swig.\n","Preparing to unpack .../22-swig_3.0.12-1_amd64.deb ...\n","Unpacking swig (3.0.12-1) ...\n","Setting up libhtml-tagset-perl (3.20-3) ...\n","Setting up libxapian30:amd64 (1.4.5-1ubuntu0.1) ...\n","Setting up swig3.0 (3.0.12-1) ...\n","Setting up libencode-locale-perl (1.05-1) ...\n","Setting up libtimedate-perl (2.3000-2) ...\n","Setting up libio-html-perl (1.001-1) ...\n","Setting up aptitude-common (0.8.10-6ubuntu1) ...\n","Setting up liblwp-mediatypes-perl (6.02-1) ...\n","Setting up liburi-perl (1.73-1) ...\n","Setting up libhtml-parser-perl (3.72-3build1) ...\n","Setting up libcgi-pm-perl (4.38-1) ...\n","Setting up libio-string-perl (1.08-3) ...\n","Setting up libsub-name-perl (0.21-1build1) ...\n","Setting up libfcgi-perl (0.78-2build1) ...\n","Setting up libsigc++-2.0-0v5:amd64 (2.10.0-2) ...\n","Setting up libclass-accessor-perl (0.51-1) ...\n","Setting up swig (3.0.12-1) ...\n","Setting up libhttp-date-perl (6.02-1) ...\n","Setting up libcgi-fast-perl (1:2.13-1) ...\n","Setting up libparse-debianchangelog-perl (1.2.0-12) ...\n","Setting up libhttp-message-perl (6.14-1) ...\n","Setting up libcwidget3v5:amd64 (0.5.17-7) ...\n","Setting up aptitude (0.8.10-6ubuntu1) ...\n","update-alternatives: using /usr/bin/aptitude-curses to provide /usr/bin/aptitude (aptitude) in auto mode\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","git is already installed at the requested version (1:2.17.1-1ubuntu0.7)\n","make is already installed at the requested version (4.1-9.1ubuntu1)\n","curl is already installed at the requested version (7.58.0-2ubuntu3.10)\n","xz-utils is already installed at the requested version (5.2.2-1.3)\n","git is already installed at the requested version (1:2.17.1-1ubuntu0.7)\n","make is already installed at the requested version (4.1-9.1ubuntu1)\n","curl is already installed at the requested version (7.58.0-2ubuntu3.10)\n","xz-utils is already installed at the requested version (5.2.2-1.3)\n","The following NEW packages will be installed:\n","  file libmagic-mgc{a} libmagic1{a} libmecab-dev libmecab2{a} mecab mecab-ipadic{a} mecab-ipadic-utf8 mecab-jumandic{a} mecab-jumandic-utf8{a} mecab-utils{a} \n","0 packages upgraded, 11 newly installed, 0 to remove and 21 not upgraded.\n","Need to get 29.3 MB of archives. After unpacking 282 MB will be used.\n","Get: 1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n","Get: 2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n","Get: 3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n","Get: 4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab2 amd64 0.996-5 [257 kB]\n","Get: 5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmecab-dev amd64 0.996-5 [308 kB]\n","Get: 6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-utils amd64 0.996-5 [4,856 B]\n","Get: 7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic-utf8 all 7.0-20130310-4 [16.2 MB]\n","Get: 8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-jumandic all 7.0-20130310-4 [2,212 B]\n","Get: 9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic all 2.7.0-20070801+main-1 [12.1 MB]\n","Get: 10 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab amd64 0.996-5 [132 kB]\n","Get: 11 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-1 [3,522 B]\n","Fetched 29.3 MB in 3s (10.5 MB/s)\n","Selecting previously unselected package libmagic-mgc.\n","(Reading database ... 145861 files and directories currently installed.)\n","Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package libmagic1:amd64.\n","Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package file.\n","Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n","Unpacking file (1:5.32-2ubuntu0.4) ...\n","Selecting previously unselected package libmecab2:amd64.\n","Preparing to unpack .../03-libmecab2_0.996-5_amd64.deb ...\n","Unpacking libmecab2:amd64 (0.996-5) ...\n","Selecting previously unselected package libmecab-dev.\n","Preparing to unpack .../04-libmecab-dev_0.996-5_amd64.deb ...\n","Unpacking libmecab-dev (0.996-5) ...\n","Selecting previously unselected package mecab-utils.\n","Preparing to unpack .../05-mecab-utils_0.996-5_amd64.deb ...\n","Unpacking mecab-utils (0.996-5) ...\n","Selecting previously unselected package mecab-jumandic-utf8.\n","Preparing to unpack .../06-mecab-jumandic-utf8_7.0-20130310-4_all.deb ...\n","Unpacking mecab-jumandic-utf8 (7.0-20130310-4) ...\n","Selecting previously unselected package mecab-jumandic.\n","Preparing to unpack .../07-mecab-jumandic_7.0-20130310-4_all.deb ...\n","Unpacking mecab-jumandic (7.0-20130310-4) ...\n","Selecting previously unselected package mecab-ipadic.\n","Preparing to unpack .../08-mecab-ipadic_2.7.0-20070801+main-1_all.deb ...\n","Unpacking mecab-ipadic (2.7.0-20070801+main-1) ...\n","Selecting previously unselected package mecab.\n","Preparing to unpack .../09-mecab_0.996-5_amd64.deb ...\n","Unpacking mecab (0.996-5) ...\n","Selecting previously unselected package mecab-ipadic-utf8.\n","Preparing to unpack .../10-mecab-ipadic-utf8_2.7.0-20070801+main-1_all.deb ...\n","Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n","Setting up libmecab2:amd64 (0.996-5) ...\n","Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n","Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n","Setting up mecab-utils (0.996-5) ...\n","Setting up mecab-ipadic (2.7.0-20070801+main-1) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up libmecab-dev (0.996-5) ...\n","Setting up file (1:5.32-2ubuntu0.4) ...\n","Setting up mecab-jumandic-utf8 (7.0-20130310-4) ...\n","Compiling Juman dictionary for Mecab.\n","reading /usr/share/mecab/dic/juman/unk.def ... 37\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/juman/AuxV.csv ... 593\n","reading /usr/share/mecab/dic/juman/Noun.koyuu.csv ... 7964\n","reading /usr/share/mecab/dic/juman/Demonstrative.csv ... 97\n","reading /usr/share/mecab/dic/juman/Prefix.csv ... 90\n","reading /usr/share/mecab/dic/juman/Emoticon.csv ... 972\n","reading /usr/share/mecab/dic/juman/Special.csv ... 158\n","reading /usr/share/mecab/dic/juman/Wikipedia.csv ... 167709\n","reading /usr/share/mecab/dic/juman/Noun.hukusi.csv ... 81\n","reading /usr/share/mecab/dic/juman/Postp.csv ... 108\n","reading /usr/share/mecab/dic/juman/ContentW.csv ... 551145\n","reading /usr/share/mecab/dic/juman/Auto.csv ... 18931\n","reading /usr/share/mecab/dic/juman/Suffix.csv ... 2128\n","reading /usr/share/mecab/dic/juman/Assert.csv ... 34\n","reading /usr/share/mecab/dic/juman/Noun.keishiki.csv ... 8\n","reading /usr/share/mecab/dic/juman/Rengo.csv ... 1118\n","reading /usr/share/mecab/dic/juman/Noun.suusi.csv ... 49\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/juman/matrix.def ... 1876x1876\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-1) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up mecab (0.996-5) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27327\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-jumandic (7.0-20130310-4) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","                            \n","Collecting mecab-python3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/06/2aeff86243c88580ccf78b136d403ce5e0a1eed9091103157f01e806499f/mecab_python3-1.0.1-cp36-cp36m-manylinux2010_x86_64.whl (3.5MB)\n","\u001b[K     |████████████████████████████████| 3.5MB 4.8MB/s \n","\u001b[?25hInstalling collected packages: mecab-python3\n","Successfully installed mecab-python3-1.0.1\n","Collecting unidic-lite\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/d2/a4233f65f718f27065a4cf23a2c4f05d8bd4c75821e092060c4efaf28e66/unidic-lite-1.0.7.tar.gz (47.3MB)\n","\u001b[K     |████████████████████████████████| 47.3MB 56kB/s \n","\u001b[?25hBuilding wheels for collected packages: unidic-lite\n","  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unidic-lite: filename=unidic_lite-1.0.7-cp36-none-any.whl size=47556594 sha256=39091071e8ed8635f2b6ecdf7ccf866c912040c3427f954f1e69ca8d7e1bde56\n","  Stored in directory: /root/.cache/pip/wheels/a8/82/7d/086724645e33a575aafd0b1dae2835c37d2c00c6a0a96ee3a0\n","Successfully built unidic-lite\n","Installing collected packages: unidic-lite\n","Successfully installed unidic-lite-1.0.7\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WfFZOvln881g"},"source":["numpy形式のテキストデータを読み込み、\n","\n","MeCabで分かち書きしたものをリスト（result）に収納します。"]},{"cell_type":"code","metadata":{"id":"hKda11rz74pT","executionInfo":{"status":"ok","timestamp":1602905156111,"user_tz":-540,"elapsed":63212,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"206ad79f-b9df-4c6b-82b9-bb0fa6f6d2b3","colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["import MeCab\n","import numpy as np\n","import pandas as pd\n","\n","\n","m = MeCab.Tagger('-Owakati')\n","\n","processed_data = np.load('data/processed_data.npy')\n","result = []\n","for text in processed_data:\n","  result.append(m.parse(text))\n","result = np.array(result)\n","np.save('data/mecab_data.npy', result)\n","result[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['第 １ の 液体 を 基材 表面 に 付与 さ れ て なる 第 １ 液 層 を 形成 する 工程 と 、 前記 第 １ 液 層 が 形成 さ れ た 前記 基材 表面 に 、 前記 第 １ の 液体 と は 非 相 溶 で あり 、 かつ 、 前記 第 １ の 液体 より も 比重 が 大きい 第 ２ の 液体 の 液滴 を インク ジェット 法 で 付与 する 工程 と 、 前記 第 １ の 液体 および 第 ２ の 液体 の 一方 の 液体 を 選択 的 に 硬化 さ せる 工程 と 、 を 有する 、 パターン 形成 方法 。 インク ジェット 法 に より 基材 表面 に 付与 さ れ た 液体 が 硬化 し て 形成 さ れ た パターン 形成 物 で あっ て 、 前記 液体 の 硬化 物 に より 形成 さ れる パターン が 有する 前記 基材 表面 に 接する 壁面 と 、 前記 基材 表面 と 、 の 間 の 角度 は 、 ４５ ° 以上 で ある 、 パターン 形成 物 。 第 １ の 液体 を 基材 表面 に 付与 する 第 １ 液体 付与 部 と 、 前記 第 １ の 液体 が 付与 さ れ た 前記 基材 表面 に 、 前記 第 １ の 液体 と は 非 相 溶 で あり 、 かつ 、 前記 第 １ の 液体 より も 比重 が 大きい 第 ２ の 液体 の 液滴 を インク ジェット 法 で 付与 する 第 ２ 液体 付与 部 と 、 前記 第 １ の 液体 および 第 ２ の 液体 の 一方 の 液体 を 選択 的 に 硬化 さ せる 選択 的 硬化 部 と 、 を 有する 、 パターン 形成 装置 。 \\n',\n","       '２ 種 以上 の 金属 に よっ て 構成 さ れる 導電 性 細線 に よっ て 構成 さ れる 、 １０００ ｃｍ２ 以上 の 面積 に わたる 導電 性 細線 パターン の 製造 方法 で あっ て 、 基材 上 に 第 １ の 金属 に よっ て 構成 さ れ た 第 １ の 導電 性 細線 を パターニング し 、 次いで 、 前記 第 １ の 導電 性 細線 に 、 前記 第 １ の 金属 と は 異なる 金属 種 で ある 第 ２ の 金属 に よっ て 構成 さ れ た 導電 性 皮膜 を 被覆 する 被覆 処理 を 施し て 、 前記 第 １ の 導電 性 細線 と 前記 導電 性 皮膜 と に よっ て 構成 さ れ た 第 ２ の 導電 性 細線 を 形成 し 、 次いで 、 前記 第 ２ の 導電 性 細線 に 、 該 第 ２ の 導電 性 細線 の 線幅 の 減少 速度 が ０ ． ５ μｍ ／ｍ ｉｎ 以下 と なる エッチング を 施し て 、 前記 第 ２ の 導電 性 細線 を 構成 する 前記 導電 性 皮膜 の 一部 が 除去 さ れ た 第 ３ の 導電 性 細線 を 形成 する こと を 特徴 と する 導電 性 細線 パターン の 製造 方法 。 \\n',\n","       '染色 液 に よる メディア へ の 着色 度合 を 調整 する 単独 で は 前記 メディア 上 で 視認 困難 な 染色 調整 剤 と 、 色材 と を 含有 する 染色 調整 インク を 前記 メディア に インク ジェット 方式 に より 塗布 する 塗布 工程 と 、 前記 染色 調整 インク が 塗布 さ れ た 前記 メディア を 前記 染色 液 に 浸漬 し て 染色 する 染色 工程 と 、 を 備える 、 染色 物 の 製造 方法 。 染色 液 に よる メディア へ の 着色 度合 を 調整 する 単独 で は 前記 メディア 上 で 視認 困難 な 染色 調整 剤 と 、 前記 染色 液 に よる 染色 工程 で 視認 でき なく なる まで 除去 さ れる 色材 と 、 を 含有 する 染色 調整 インク ジェット インク 。 染色 液 に よる メディア へ の 着色 度合 を 調整 する 単独 で は 前記 メディア 上 で 視認 困難 な 染色 調整 剤 と 、 前記 染色 液 に よる 染色 工程 で 視認 可能 な 程度 に 残存 する 色材 と 、 を 含有 する 染色 調整 インク ジェット インク 。 染色 液 に よる メディア へ の 着色 度合 を 調整 する 単独 で は 前記 メディア 上 で 視認 困難 な 染色 調整 剤 と 、 前記 染色 液 に よる 染色 工程 で 視認 可能 な 程度 に 残存 する 第 １ の 色材 と 、 を 含有 する 第 １ の 染色 調整 インク ジェット インク と 、 前記 染色 調整 剤 と 、 前記 染 . . . \\n',\n","       '着色 剤 、 アラビア ガム 、 炭素 数 １２ 以上 、 ２０ 以下 の 高級 アルコール 、 炭素 数 １ 以上 、 ４ 以下 の 低級 アルコール 、 お よび水 を 含む インク ジェット インク 。 \\n',\n","       '少なく とも 前 処理 液 と インク と から なる インク ジェット 記録 液 セット で あっ て 、 前記 前 処理 液 が 、 少なく とも 、 ポリエステル 、 ポリオレフィン 又 は ポリウレタン の 骨格 の いずれ か を 含む 水 不溶 性 樹脂 微 粒子 と 凝集 剤 と 水 と を 含有 し 、 前記 インク が 、 少なく とも 、 顔料 と オキサゾリン 基 を 有する 化合 物 と 水 と を 含有 する 、 こと を 特徴 と する インク ジェット 記録 液 セット 。 \\n',\n","       'インク ジェット 用 の 水性 インク の 製造 方法 で あっ て 、 顔料 、 及び 界面 活性 剤 を 混合 し て 混合 物 を 得る 工程 と 、 得 られ た 前記 混合 物 、 及び その 他 の インク 成分 を 混合 する 工程 と 、 を 有し 、 前記 顔料 が 、 顔料 の 粒子 表面 に 、 （ ｉ ） アニオン 性 基 、 及び 、 （ ｉｉ ） 他 の 原子 団 と アニオン 性 基 と が 結合 し た 基 、 から なる 群 より 選択 さ れる 官能 基 が 結合 し た 自己 分散 顔料 で ある と とも に 、 前記 官 能基 の 密度 が 、 ０ ． １０ μｍ ｏｌ ／ｍ 2 以上 ０ ． ４８ μｍ ｏｌ ／ｍ 2 以下 で あり 、 前記 界面 活性 剤 が 、 陽 イオン と なり うる 窒素 原子 が 第 ２ 級 アミン 又 は 第 ３ 級 アミン の 構造 を 有する アミノ 酸 型 界面 活性 剤 で ある こと を 特徴 と する 水性 インク の 製造 方法 。 \\n',\n","       '水性 媒体 と 、 スクアリリウム 骨格 を 有する 化合 物 と 樹脂 と を 含有 する 赤外 線 吸収 性 粒子 と 、 ジアルキルスルホコハク 酸 塩 と 、 赤色 アゾ 顔料 と 、 を 含む 水性 インク 。 水性 媒体 と 、 スクアリリウム 骨格 を 有する 化合 物 と 樹脂 と を 含有 する 赤外 線 吸収 性 粒子 と 、 ジアルキルスルホコハク 酸 塩 と 、 赤色 顔料 と 、 を 含み 、 ６０ ℃ の 環境 下 で １４ 日間 経過 する こと に よる 前記 赤外 線 吸収 性 粒子 に おけ る 赤外 線 吸光 係数 の 低下 率 が ５ ％ 以下 で ある 水性 インク 。 \\n',\n","       '平均 粒子 径 が ０ ． ４ ～ ２ ． ５ μｍ で あり 、 屈折 率 が １ ． ４ ～ １ ． ７ で あり 、 比重 が ２ ． １ 以下 で ある 粒子 を 含む 、 インク ジェット インク 。 \\n',\n","       '発光 性 ナノ 結晶 粒子 を 含有 する 少なく とも １ 種 の 発光 性 インク 組成 物 と 、 光 散乱 性 粒子 を 含有 する 非 発光 性 インク 組成 物 と 、 を 含む 、 インク 組成 物 セット 。 発光 性 ナノ 結晶 粒子 を 含有 する 少なく とも １ 種 の 発光 性 画素 部 と 、 光 散乱 性 粒子 を 含有 する 非 発光 性 画素 部 と 、 を 備える 、 光 変換 層 。 \\n',\n","       '少なく とも インク ジェット インク と 前 処理 液 を 含む インク ジェット 記録 液 セット で あっ て 、 前記 インク ジェット インク が 、 少なく とも 顔料 、 顔料 分散 剤 、 水溶 性 有機 溶媒 及び 水 不溶 性 樹脂 を 含有 し 、 当該 水 不溶 性 樹脂 が 、 ポリエステル 骨格 、 ポリオレフィン 骨格 又 は ポリウレタン 骨格 の いずれ か を 含む 水 不溶 性 樹脂 で あり 、 前記 前 処理 液 が 、 少なく とも 凝集 剤 及び 水 不溶 性 樹脂 微 粒子 を 含有 し 、 当該 水 不溶 性 樹脂 微 粒子 が 、 ポリオレフィン 系 樹脂 が ポリウレタン 系 樹脂 に 含有 さ れ た 複合 樹脂 粒子 で ある こと を 特徴 と する インク ジェット 記録 液 セット 。 \\n'],\n","      dtype='<U843')"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"L1Fv87VEA6z_"},"source":["## [sentencepiece](https://pypi.org/project/sentencepiece/)\n","\n","サブワード法として最も有名な方法です。\n","\n","あらかじめ学習済みモデルとして、\n","\n","[BERT with SentencePiece を日本語 Wikipedia で学習してモデルを公開しました｜原理的には可能](https://yoheikikuta.github.io/bert-japanese/)\n","\n","が公開している [google Drive](https://drive.google.com/drive/folders/1Zsm9DD40lrUVu6iAnIuTH2ODIkh-WM-O) 上のデータ から 'wiki-ja.model' をダウンロードして　'./data'　に保存しておきます。\n"]},{"cell_type":"code","metadata":{"id":"2dpbGklbEU0f","executionInfo":{"status":"ok","timestamp":1603066559889,"user_tz":-540,"elapsed":4148,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"500ce0f0-666a-45e5-cd90-590aa294b201","colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\r\u001b[K     |▎                               | 10kB 19.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 4.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 4.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 4.0MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 4.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 245kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 256kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 266kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 276kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 286kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 296kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 307kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 317kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 327kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 337kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 348kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 358kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 368kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 378kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 389kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 399kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 409kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 419kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 430kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 440kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 450kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 460kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 471kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 481kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 491kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 501kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 512kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 522kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 532kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 542kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 552kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 563kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 573kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 583kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 593kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 604kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 614kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 624kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 634kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 645kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 655kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 665kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 675kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 686kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 696kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 706kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 716kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 727kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 737kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 747kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 757kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 768kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 778kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 788kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 798kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 808kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 819kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 829kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 839kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 849kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 860kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 870kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 880kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 890kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 901kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 911kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 921kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 931kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 942kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 952kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 962kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 972kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 983kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 993kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.0MB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.0MB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 4.8MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.91\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gy4RR6OdBPuv","executionInfo":{"status":"ok","timestamp":1603066589074,"user_tz":-540,"elapsed":1733,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"60e1d8f1-8799-44a1-e91f-edb02e9b0c3f","colab":{"base_uri":"https://localhost:8080/","height":237}},"source":["import sentencepiece as spm\n","import numpy as np\n","\n","sp = spm.SentencePieceProcessor()\n","sp.load('data/wiki-ja.model')\n","\n","processed_data = np.load('data/processed_data.npy')\n","result = []\n","for text in processed_data:\n","  result.append(' '.join(sp.EncodeAsPieces(text)))\n","result = np.array(result)\n","np.save('data/sentencepiece_data.npy', result)\n","result[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['▁第 1 の 液体 を 基 材 表面に 付与 されて なる 第 1 液 層 を形成する 工程 と 、 前 記 第 1 液 層 が 形成された 前 記 基 材 表面に 、 前 記 第 1 の 液体 とは 非 相 溶 であり 、 かつ 、 前 記 第 1 の 液体 よりも 比重 が大きい 第 2 の 液体 の 液 滴 を インク ジェット 法 で 付与 する 工程 と 、 前 記 第 1 の 液体 および 第 2 の 液体 の 一方 の 液体 を 選択 的に 硬化 させる 工程 と 、 を有する 、 パターン 形成 方法 。 インク ジェット 法により 基 材 表面に 付与 された 液体 が 硬化 して 形成された パターン 形成 物 であって 、 前 記 液体 の 硬化 物 により 形成される パターン が 有 する 前 記 基 材 表面 に接する 壁面 と 、 前 記 基 材 表面 と 、 の間の 角度 は 、 45 ° 以上 である 、 パターン 形成 物 。 第 1 の 液体 を 基 材 表面に 付与 する 第 1 液体 付与 部 と 、 前 記 第 1 の 液体 が付与され た 前 記 基 材 表面に 、 前 記 第 1 の 液体 とは 非 相 溶 であり 、 かつ 、 前 記 第 1 の 液体 よりも 比重 が大きい 第 2 の 液体 の 液 滴 を インク ジェット 法 で 付与 する 第 2 液体 付与 部 と 、 前 記 第 1 の 液体 および 第 2 の 液体 の 一方 の 液体 を 選択 的に 硬化 させる 選択 的 硬化 部 と 、 を有する 、 パターン 形成 装置 。',\n","       '▁2 種 以上の 金属 によって 構成 される 導 電 性 細 線 によって 構成 される 、 1000 cm 2 以上の 面積 にわたる 導 電 性 細 線 パターン の製造 方法 であって 、 基 材 上に 第 1 の 金属 によって 構成 された 第 1 の 導 電 性 細 線を パ ター ニング し 、 次いで 、 前 記 第 1 の 導 電 性 細 線 に 、 前 記 第 1 の 金属 とは異なる 金属 種である 第 2 の 金属 によって 構成 された 導 電 性 皮 膜 を 被覆 する 被覆 処理 を施し て 、 前 記 第 1 の 導 電 性 細 線と 前 記 導 電 性 皮 膜 と によって 構成 された 第 2 の 導 電 性 細 線 を形成し 、 次いで 、 前 記 第 2 の 導 電 性 細 線 に 、 該 第 2 の 導 電 性 細 線の 線 幅 の減少 速度 が 0.5 μ m / min 以下 となる エ ッチ ング を施し て 、 前 記 第 2 の 導 電 性 細 線 を構成する 前 記 導 電 性 皮 膜 の一部が 除去 された 第 3 の 導 電 性 細 線 を形成する こと を特徴とする 導 電 性 細 線 パターン の製造 方法 。',\n","       '▁ 染色 液 による メディア への 着 色 度 合 を調整する 単独で は 前 記 メディア 上で 視認 困難な 染色 調整 剤 と 、 色 材 と を 含有 する 染色 調整 インク を 前 記 メディア に インク ジェット 方式 により 塗 布 する 塗 布 工程 と 、 前 記 染色 調整 インク が 塗 布 された 前 記 メディア を 前 記 染色 液 に 浸 漬 して 染色 する 染色 工程 と 、 を備える 、 染色 物 の製造 方法 。 染色 液 による メディア への 着 色 度 合 を調整する 単独で は 前 記 メディア 上で 視認 困難な 染色 調整 剤 と 、 前 記 染色 液 による 染色 工程 で 視認 できなくなる まで 除去 される 色 材 と 、 を 含有 する 染色 調整 インク ジェット インク 。 染色 液 による メディア への 着 色 度 合 を調整する 単独で は 前 記 メディア 上で 視認 困難な 染色 調整 剤 と 、 前 記 染色 液 による 染色 工程 で 視認 可能な 程度 に 残存 する 色 材 と 、 を 含有 する 染色 調整 インク ジェット インク 。 染色 液 による メディア への 着 色 度 合 を調整する 単独で は 前 記 メディア 上で 視認 困難な 染色 調整 剤 と 、 前 記 染色 液 による 染色 工程 で 視認 可能な 程度 に 残存 する 第 1 の色 材 と 、 を 含有 する 第 1 の 染色 調整 インク ジェット インク と 、 前 記 染色 調整 剤 と 、 前 記 染 ...',\n","       '▁ 着 色 剤 、 アラビア ガム 、 炭素 数 12 以上 、 20 以下の 高級 アルコール 、 炭素 数 1 以上 、 4 以下の 低 級 アルコール 、 および 水 を含む インク ジェット インク 。',\n","       '▁ 少なくとも 前 処理 液 と インク と からなる インク ジェット 記録 液 セット であって 、 前 記 前 処理 液 が 、 少なくとも 、 ポリ エステル 、 ポリ オレ フィン 又は ポリ ウ レ タン の 骨格 のいずれか を含む 水 不 溶 性 樹脂 微 粒子 と 凝 集 剤 と 水 と を 含有 し 、 前 記 インク が 、 少なくとも 、 顔料 と オキ サ ゾ リン 基 を有する 化合物 と 水 と を 含有 する 、 こと を特徴とする インク ジェット 記録 液 セット 。',\n","       '▁ インク ジェット 用の 水 性 インク の製造 方法 であって 、 顔料 、 及び 界 面 活性 剤 を 混合 して 混合 物 を得る 工程 と 、 得られた 前 記 混合 物 、 及び その他の インク 成分 を 混合 する 工程 と 、 を有し 、 前 記 顔料 が 、 顔料 の 粒子 表面に 、 ( i ) ア ニオン 性 基 、 及び 、 ( ii ) 他の 原子 団 と ア ニオン 性 基 と が 結合 した 基 、 からなる 群 より 選択 される 官 能 基 が 結合 した 自己 分散 顔料 である とともに 、 前 記 官 能 基の 密度 が 、 0.1 0 μ mol / m 2 以上 0.4 8 μ mol / m 2 以下 であり 、 前 記 界 面 活性 剤 が 、 陽 イオン となり うる 窒素 原子 が 第 2 級 アミン 又は 第 3 級 アミン の構造 を有する アミノ酸 型 界 面 活性 剤 であること を特徴とする 水 性 インク の製造 方法 。',\n","       '▁ 水 性 媒体 と 、 スク アリ リウム 骨格 を有する 化合物 と 樹脂 と を 含有 する 赤外線 吸収 性 粒子 と 、 ジ アル キル スル ホ コ ハク 酸 塩 と 、 赤色 ア ゾ 顔料 と 、 を含む 水 性 インク 。 水 性 媒体 と 、 スク アリ リウム 骨格 を有する 化合物 と 樹脂 と を 含有 する 赤外線 吸収 性 粒子 と 、 ジ アル キル スル ホ コ ハク 酸 塩 と 、 赤色 顔料 と 、 を含み 、 6 0° C の 環境 下で 14 日間 経過 すること による 前 記 赤外線 吸収 性 粒子 における 赤外線 吸 光 係数 の低下 率が 5% 以下 である 水 性 インク 。',\n","       '▁ 平均 粒子 径 が 0.4 ～ 2.5 μ m であり 、 屈折 率が 1.4 ～ 1.7 であり 、 比重 が 2.1 以下 である 粒子 を含む 、 インク ジェット インク 。',\n","       '▁ 発光 性 ナノ 結晶 粒子 を 含有 する 少なくとも 1 種の 発光 性 インク 組成 物 と 、 光 散乱 性 粒子 を 含有 する 非 発光 性 インク 組成 物 と 、 を含む 、 インク 組成 物 セット 。 発光 性 ナノ 結晶 粒子 を 含有 する 少なくとも 1 種の 発光 性 画素 部 と 、 光 散乱 性 粒子 を 含有 する 非 発光 性 画素 部 と 、 を備える 、 光 変換 層 。',\n","       '▁ 少なくとも インク ジェット インク と 前 処理 液 を含む インク ジェット 記録 液 セット であって 、 前 記 インク ジェット インク が 、 少なくとも 顔料 、 顔料 分散 剤 、 水 溶 性 有機 溶媒 及び 水 不 溶 性 樹脂 を 含有 し 、 当該 水 不 溶 性 樹脂 が 、 ポリ エステル 骨格 、 ポリ オレ フィン 骨格 又は ポリ ウ レ タン 骨格 のいずれか を含む 水 不 溶 性 樹脂 であり 、 前 記 前 処理 液 が 、 少なくとも 凝 集 剤 及び 水 不 溶 性 樹脂 微 粒子 を 含有 し 、 当該 水 不 溶 性 樹脂 微 粒子 が 、 ポリ オレ フィン 系 樹脂 が ポリ ウ レ タン 系 樹脂 に 含有 された 複合 樹脂 粒子 であること を特徴とする インク ジェット 記録 液 セット 。'],\n","      dtype='<U851')"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"uakHv4wbBwYe","executionInfo":{"status":"ok","timestamp":1601718936124,"user_tz":-540,"elapsed":642,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"915d9d89-8b7f-437f-e143-1c1e34ea9dff","colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["# おまけ　テキストを単語ID列に変換することもできます。\n","import sentencepiece as spm\n","import numpy as pd\n","\n","sp = spm.SentencePieceProcessor()\n","sp.load('data/wiki-ja.model')\n","result = []\n","maxlen = 0\n","for text in processed_data:\n","  processed_text = sp.EncodeAsIds(text)\n","  result.append(processed_text)\n","  if len(processed_text) > maxlen:\n","    maxlen = len(processed_text)\n","# zero padding で文書の長さをを揃える\n","for i, processed_text in enumerate(result):\n","  result[i] = result[i]+[0]*(maxlen-len(result[i]))\n","result = np.array(result)\n","print(result[:10], '\\n', result.shape, '次元')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[    9 25062  3591 ...     0     0     0]\n"," [    9   447   502 ...     0     0     0]\n"," [    9  4694   217 ...     0     0     0]\n"," ...\n"," [    9  4694 17230 ...     0     0     0]\n"," [    9 17230  4965 ...     0     0     0]\n"," [    9   659 12324 ...     0     0     0]] \n"," (50, 304) 次元\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FK6Eozu1OxGo"},"source":["## n-gram\n","\n","単純に n文字 で分割しますが、nが2以上の時、重なり合うように切り出す工夫が必要です。"]},{"cell_type":"code","metadata":{"id":"SH3T3ieYMb3D","executionInfo":{"status":"ok","timestamp":1603066367675,"user_tz":-540,"elapsed":1781,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"b1acfa4d-ceaf-4d60-c025-ee852284ef69","colab":{"base_uri":"https://localhost:8080/","height":237}},"source":["n = 3 \n","\n","def ngram(words, n):\n","  # n文字ずつ切り出し、1文字×nのタプル生成\n","  # ('染', '色', '液'), ('色', '液', 'に'), ('液', 'に', 'よ')\n","  ngram = list(zip(*(words[i:] for i in range(n))))\n","  # n文字の文字列リストに変換　'染色液', '色液に', '液によ', 'による'\n","  # リストの要素をスペースで連結して一つの文字列にする\n","  return ' '.join([''.join(j) for j in ngram])\n","\n","processed_data = np.load('data/processed_data.npy')\n","result = []\n","for text in processed_data:\n","  result.append(ngram(text, n))\n","result = np.array(result)\n","np.save('data/'+str(n)+'gram_data.npy', result)\n","result[:10]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['第１の １の液 の液体 液体を 体を基 を基材 基材表 材表面 表面に 面に付 に付与 付与さ 与され されて れてな てなる なる第 る第１ 第１液 １液層 液層を 層を形 を形成 形成す 成する する工 る工程 工程と 程と、 と、前 、前記 前記第 記第１ 第１液 １液層 液層が 層が形 が形成 形成さ 成され された れた前 た前記 前記基 記基材 基材表 材表面 表面に 面に、 に、前 、前記 前記第 記第１ 第１の １の液 の液体 液体と 体とは とは非 は非相 非相溶 相溶で 溶であ であり あり、 り、か 、かつ かつ、 つ、前 、前記 前記第 記第１ 第１の １の液 の液体 液体よ 体より よりも りも比 も比重 比重が 重が大 が大き 大きい きい第 い第２ 第２の ２の液 の液体 液体の 体の液 の液滴 液滴を 滴をイ をイン インク ンクジ クジェ ジェッ ェット ット法 ト法で 法で付 で付与 付与す 与する する工 る工程 工程と 程と、 と、前 、前記 前記第 記第１ 第１の １の液 の液体 液体お 体およ および よび第 び第２ 第２の ２の液 の液体 液体の 体の一 の一方 一方の 方の液 の液体 液体を 体を選 を選択 選択的 択的に 的に硬 に硬化 硬化さ 化させ させる せる工 る工程 工程と 程と、 と、を 、を有 を有す 有する する、 る、パ 、パタ パター ターン ーン形 ン形成 形成方 成方法 方法。 法。イ 。イン インク ンクジ クジェ ジェッ ェット ット法 ト法に 法によ により より基 り基材 基材表 材表面 表面に 面に付 に付与 付与さ 与され された れた液 た液体 液体が 体が硬 が硬化 硬化し 化して して形 て形成 形成さ 成され された れたパ たパタ パター ターン ーン形 ン形成 形成物 成物で 物であ であっ あって って、 て、前 、前記 前記液 記液体 液体の 体の硬 の硬化 硬化物 化物に 物によ により より形 り形成 形成さ 成され される れるパ るパタ パター ターン ーンが ンが有 が有す 有する する前 る前記 前記基 記基材 基材表 材表面 表面に 面に接 に接す 接する する壁 る壁面 壁面と 面と、 と、前 、前記 前記基 記基材 基材表 材表面 表面と 面と、 と、の 、の間 の間の 間の角 の角度 角度は 度は、 は、４ 、４５ ４５° ５°以 °以上 以上で 上であ である ある、 る、パ 、パタ パター ターン ーン形 ン形成 形成物 成物。 物。第 。第１ 第１の １の液 の液体 液体を 体を基 を基材 基材表 材表面 表面に 面に付 に付与 付与す 与する する第 る第１ 第１液 １液体 液体付 体付与 付与部 与部と 部と、 と、前 、前記 前記第 記第１ 第１の １の液 の液体 液体が 体が付 が付与 付与さ 与され された れた前 た前記 前記基 記基材 基材表 材表面 表面に 面に、 に、前 、前記 前記第 記第１ 第１の １の液 の液体 液体と 体とは とは非 は非相 非相溶 相溶で 溶であ であり あり、 り、か 、かつ かつ、 つ、前 、前記 前記第 記第１ 第１の １の液 の液体 液体よ 体より よりも りも比 も比重 比重が 重が大 が大き 大きい きい第 い第２ 第２の ２の液 の液体 液体の 体の液 の液滴 液滴を 滴をイ をイン インク ンクジ クジェ ジェッ ェット ット法 ト法で 法で付 で付与 付与す 与する する第 る第２ 第２液 ２液体 液体付 体付与 付与部 与部と 部と、 と、前 、前記 前記第 記第１ 第１の １の液 の液体 液体お 体およ および よび第 び第２ 第２の ２の液 の液体 液体の 体の一 の一方 一方の 方の液 の液体 液体を 体を選 を選択 選択的 択的に 的に硬 に硬化 硬化さ 化させ させる せる選 る選択 選択的 択的硬 的硬化 硬化部 化部と 部と、 と、を 、を有 を有す 有する する、 る、パ 、パタ パター ターン ーン形 ン形成 形成装 成装置 装置。',\n","       '２種以 種以上 以上の 上の金 の金属 金属に 属によ によっ よって って構 て構成 構成さ 成され される れる導 る導電 導電性 電性細 性細線 細線に 線によ によっ よって って構 て構成 構成さ 成され される れる、 る、１ 、１０ １００ ０００ ００ｃ ０ｃｍ ｃｍ２ ｍ２以 ２以上 以上の 上の面 の面積 面積に 積にわ にわた わたる たる導 る導電 導電性 電性細 性細線 細線パ 線パタ パター ターン ーンの ンの製 の製造 製造方 造方法 方法で 法であ であっ あって って、 て、基 、基材 基材上 材上に 上に第 に第１ 第１の １の金 の金属 金属に 属によ によっ よって って構 て構成 構成さ 成され された れた第 た第１ 第１の １の導 の導電 導電性 電性細 性細線 細線を 線をパ をパタ パター ターニ ーニン ニング ングし グし、 し、次 、次い 次いで いで、 で、前 、前記 前記第 記第１ 第１の １の導 の導電 導電性 電性細 性細線 細線に 線に、 に、前 、前記 前記第 記第１ 第１の １の金 の金属 金属と 属とは とは異 は異な 異なる なる金 る金属 金属種 属種で 種であ である ある第 る第２ 第２の ２の金 の金属 金属に 属によ によっ よって って構 て構成 構成さ 成され された れた導 た導電 導電性 電性皮 性皮膜 皮膜を 膜を被 を被覆 被覆す 覆する する被 る被覆 被覆処 覆処理 処理を 理を施 を施し 施して して、 て、前 、前記 前記第 記第１ 第１の １の導 の導電 導電性 電性細 性細線 細線と 線と前 と前記 前記導 記導電 導電性 電性皮 性皮膜 皮膜と 膜とに とによ によっ よって って構 て構成 構成さ 成され された れた第 た第２ 第２の ２の導 の導電 導電性 電性細 性細線 細線を 線を形 を形成 形成し 成し、 し、次 、次い 次いで いで、 で、前 、前記 前記第 記第２ 第２の ２の導 の導電 導電性 電性細 性細線 細線に 線に、 に、該 、該第 該第２ 第２の ２の導 の導電 導電性 電性細 性細線 細線の 線の線 の線幅 線幅の 幅の減 の減少 減少速 少速度 速度が 度が０ が０． ０．５ ．５μ ５μｍ μｍ／ ｍ／ｍ ／ｍｉ ｍｉｎ ｉｎ以 ｎ以下 以下と 下とな となる なるエ るエッ エッチ ッチン チング ングを グを施 を施し 施して して、 て、前 、前記 前記第 記第２ 第２の ２の導 の導電 導電性 電性細 性細線 細線を 線を構 を構成 構成す 成する する前 る前記 前記導 記導電 導電性 電性皮 性皮膜 皮膜の 膜の一 の一部 一部が 部が除 が除去 除去さ 去され された れた第 た第３ 第３の ３の導 の導電 導電性 電性細 性細線 細線を 線を形 を形成 形成す 成する するこ ること ことを とを特 を特徴 特徴と 徴とす とする する導 る導電 導電性 電性細 性細線 細線パ 線パタ パター ターン ーンの ンの製 の製造 製造方 造方法 方法。',\n","       '染色液 色液に 液によ による よるメ るメデ メディ ディア ィアへ アへの への着 の着色 着色度 色度合 度合を 合を調 を調整 調整す 整する する単 る単独 単独で 独では では前 は前記 前記メ 記メデ メディ ディア ィア上 ア上で 上で視 で視認 視認困 認困難 困難な 難な染 な染色 染色調 色調整 調整剤 整剤と 剤と、 と、色 、色材 色材と 材とを とを含 を含有 含有す 有する する染 る染色 染色調 色調整 調整イ 整イン インク ンクを クを前 を前記 前記メ 記メデ メディ ディア ィアに アにイ にイン インク ンクジ クジェ ジェッ ェット ット方 ト方式 方式に 式によ により より塗 り塗布 塗布す 布する する塗 る塗布 塗布工 布工程 工程と 程と、 と、前 、前記 前記染 記染色 染色調 色調整 調整イ 整イン インク ンクが クが塗 が塗布 塗布さ 布され された れた前 た前記 前記メ 記メデ メディ ディア ィアを アを前 を前記 前記染 記染色 染色液 色液に 液に浸 に浸漬 浸漬し 漬して して染 て染色 染色す 色する する染 る染色 染色工 色工程 工程と 程と、 と、を 、を備 を備え 備える える、 る、染 、染色 染色物 色物の 物の製 の製造 製造方 造方法 方法。 法。染 。染色 染色液 色液に 液によ による よるメ るメデ メディ ディア ィアへ アへの への着 の着色 着色度 色度合 度合を 合を調 を調整 調整す 整する する単 る単独 単独で 独では では前 は前記 前記メ 記メデ メディ ディア ィア上 ア上で 上で視 で視認 視認困 認困難 困難な 難な染 な染色 染色調 色調整 調整剤 整剤と 剤と、 と、前 、前記 前記染 記染色 染色液 色液に 液によ による よる染 る染色 染色工 色工程 工程で 程で視 で視認 視認で 認でき できな きなく なくな くなる なるま るまで まで除 で除去 除去さ 去され される れる色 る色材 色材と 材と、 と、を 、を含 を含有 含有す 有する する染 る染色 染色調 色調整 調整イ 整イン インク ンクジ クジェ ジェッ ェット ットイ トイン インク ンク。 ク。染 。染色 染色液 色液に 液によ による よるメ るメデ メディ ディア ィアへ アへの への着 の着色 着色度 色度合 度合を 合を調 を調整 調整す 整する する単 る単独 単独で 独では では前 は前記 前記メ 記メデ メディ ディア ィア上 ア上で 上で視 で視認 視認困 認困難 困難な 難な染 な染色 染色調 色調整 調整剤 整剤と 剤と、 と、前 、前記 前記染 記染色 染色液 色液に 液によ による よる染 る染色 染色工 色工程 工程で 程で視 で視認 視認可 認可能 可能な 能な程 な程度 程度に 度に残 に残存 残存す 存する する色 る色材 色材と 材と、 と、を 、を含 を含有 含有す 有する する染 る染色 染色調 色調整 調整イ 整イン インク ンクジ クジェ ジェッ ェット ットイ トイン インク ンク。 ク。染 。染色 染色液 色液に 液によ による よるメ るメデ メディ ディア ィアへ アへの への着 の着色 着色度 色度合 度合を 合を調 を調整 調整す 整する する単 る単独 単独で 独では では前 は前記 前記メ 記メデ メディ ディア ィア上 ア上で 上で視 で視認 視認困 認困難 困難な 難な染 な染色 染色調 色調整 調整剤 整剤と 剤と、 と、前 、前記 前記染 記染色 染色液 色液に 液によ による よる染 る染色 染色工 色工程 工程で 程で視 で視認 視認可 認可能 可能な 能な程 な程度 程度に 度に残 に残存 残存す 存する する第 る第１ 第１の １の色 の色材 色材と 材と、 と、を 、を含 を含有 含有す 有する する第 る第１ 第１の １の染 の染色 染色調 色調整 調整イ 整イン インク ンクジ クジェ ジェッ ェット ットイ トイン インク ンクと クと、 と、前 、前記 前記染 記染色 染色調 色調整 調整剤 整剤と 剤と、 と、前 、前記 前記染 記染. 染.. ...',\n","       '着色剤 色剤、 剤、ア 、アラ アラビ ラビア ビアガ アガム ガム、 ム、炭 、炭素 炭素数 素数１ 数１２ １２以 ２以上 以上、 上、２ 、２０ ２０以 ０以下 以下の 下の高 の高級 高級ア 級アル アルコ ルコー コール ール、 ル、炭 、炭素 炭素数 素数１ 数１以 １以上 以上、 上、４ 、４以 ４以下 以下の 下の低 の低級 低級ア 級アル アルコ ルコー コール ール、 ル、お 、およ および よび水 び水を 水を含 を含む 含むイ むイン インク ンクジ クジェ ジェッ ェット ットイ トイン インク ンク。',\n","       '少なく なくと くとも とも前 も前処 前処理 処理液 理液と 液とイ とイン インク ンクと クとか とから からな らなる なるイ るイン インク ンクジ クジェ ジェッ ェット ット記 ト記録 記録液 録液セ 液セッ セット ットで トであ であっ あって って、 て、前 、前記 前記前 記前処 前処理 処理液 理液が 液が、 が、少 、少な 少なく なくと くとも とも、 も、ポ 、ポリ ポリエ リエス エステ ステル テル、 ル、ポ 、ポリ ポリオ リオレ オレフ レフィ フィン ィン又 ン又は 又はポ はポリ ポリウ リウレ ウレタ レタン タンの ンの骨 の骨格 骨格の 格のい のいず いずれ ずれか れかを かを含 を含む 含む水 む水不 水不溶 不溶性 溶性樹 性樹脂 樹脂微 脂微粒 微粒子 粒子と 子と凝 と凝集 凝集剤 集剤と 剤と水 と水と 水とを とを含 を含有 含有し 有し、 し、前 、前記 前記イ 記イン インク ンクが クが、 が、少 、少な 少なく なくと くとも とも、 も、顔 、顔料 顔料と 料とオ とオキ オキサ キサゾ サゾリ ゾリン リン基 ン基を 基を有 を有す 有する する化 る化合 化合物 合物と 物と水 と水と 水とを とを含 を含有 含有す 有する する、 る、こ 、こと ことを とを特 を特徴 特徴と 徴とす とする するイ るイン インク ンクジ クジェ ジェッ ェット ット記 ト記録 記録液 録液セ 液セッ セット ット。',\n","       'インク ンクジ クジェ ジェッ ェット ット用 ト用の 用の水 の水性 水性イ 性イン インク ンクの クの製 の製造 製造方 造方法 方法で 法であ であっ あって って、 て、顔 、顔料 顔料、 料、及 、及び 及び界 び界面 界面活 面活性 活性剤 性剤を 剤を混 を混合 混合し 合して して混 て混合 混合物 合物を 物を得 を得る 得る工 る工程 工程と 程と、 と、得 、得ら 得られ られた れた前 た前記 前記混 記混合 混合物 合物、 物、及 、及び 及びそ びその その他 の他の 他のイ のイン インク ンク成 ク成分 成分を 分を混 を混合 混合す 合する する工 る工程 工程と 程と、 と、を 、を有 を有し 有し、 し、前 、前記 前記顔 記顔料 顔料が 料が、 が、顔 、顔料 顔料の 料の粒 の粒子 粒子表 子表面 表面に 面に、 に、（ 、（ｉ （ｉ） ｉ）ア ）アニ アニオ ニオン オン性 ン性基 性基、 基、及 、及び 及び、 び、（ 、（ｉ （ｉｉ ｉｉ） ｉ）他 ）他の 他の原 の原子 原子団 子団と 団とア とアニ アニオ ニオン オン性 ン性基 性基と 基とが とが結 が結合 結合し 合した した基 た基、 基、か 、から からな らなる なる群 る群よ 群より より選 り選択 選択さ 択され される れる官 る官能 官能基 能基が 基が結 が結合 結合し 合した した自 た自己 自己分 己分散 分散顔 散顔料 顔料で 料であ である あると るとと ととも ともに もに、 に、前 、前記 前記官 記官能 官能基 能基の 基の密 の密度 密度が 度が、 が、０ 、０． ０．１ ．１０ １０μ ０μｍ μｍｏ ｍｏｌ ｏｌ／ ｌ／ｍ ／ｍ2 ｍ2以 2以上 以上０ 上０． ０．４ ．４８ ４８μ ８μｍ μｍｏ ｍｏｌ ｏｌ／ ｌ／ｍ ／ｍ2 ｍ2以 2以下 以下で 下であ であり あり、 り、前 、前記 前記界 記界面 界面活 面活性 活性剤 性剤が 剤が、 が、陽 、陽イ 陽イオ イオン オンと ンとな となり なりう りうる うる窒 る窒素 窒素原 素原子 原子が 子が第 が第２ 第２級 ２級ア 級アミ アミン ミン又 ン又は 又は第 は第３ 第３級 ３級ア 級アミ アミン ミンの ンの構 の構造 構造を 造を有 を有す 有する するア るアミ アミノ ミノ酸 ノ酸型 酸型界 型界面 界面活 面活性 活性剤 性剤で 剤であ である あるこ ること ことを とを特 を特徴 特徴と 徴とす とする する水 る水性 水性イ 性イン インク ンクの クの製 の製造 製造方 造方法 方法。',\n","       '水性媒 性媒体 媒体と 体と、 と、ス 、スク スクア クアリ アリリ リリウ リウム ウム骨 ム骨格 骨格を 格を有 を有す 有する する化 る化合 化合物 合物と 物と樹 と樹脂 樹脂と 脂とを とを含 を含有 含有す 有する する赤 る赤外 赤外線 外線吸 線吸収 吸収性 収性粒 性粒子 粒子と 子と、 と、ジ 、ジア ジアル アルキ ルキル キルス ルスル スルホ ルホコ ホコハ コハク ハク酸 ク酸塩 酸塩と 塩と、 と、赤 、赤色 赤色ア 色アゾ アゾ顔 ゾ顔料 顔料と 料と、 と、を 、を含 を含む 含む水 む水性 水性イ 性イン インク ンク。 ク。水 。水性 水性媒 性媒体 媒体と 体と、 と、ス 、スク スクア クアリ アリリ リリウ リウム ウム骨 ム骨格 骨格を 格を有 を有す 有する する化 る化合 化合物 合物と 物と樹 と樹脂 樹脂と 脂とを とを含 を含有 含有す 有する する赤 る赤外 赤外線 外線吸 線吸収 吸収性 収性粒 性粒子 粒子と 子と、 と、ジ 、ジア ジアル アルキ ルキル キルス ルスル スルホ ルホコ ホコハ コハク ハク酸 ク酸塩 酸塩と 塩と、 と、赤 、赤色 赤色顔 色顔料 顔料と 料と、 と、を 、を含 を含み 含み、 み、６ 、６０ ６０℃ ０℃の ℃の環 の環境 環境下 境下で 下で１ で１４ １４日 ４日間 日間経 間経過 経過す 過する するこ ること ことに とによ による よる前 る前記 前記赤 記赤外 赤外線 外線吸 線吸収 吸収性 収性粒 性粒子 粒子に 子にお におけ おける ける赤 る赤外 赤外線 外線吸 線吸光 吸光係 光係数 係数の 数の低 の低下 低下率 下率が 率が５ が５％ ５％以 ％以下 以下で 下であ である ある水 る水性 水性イ 性イン インク ンク。',\n","       '平均粒 均粒子 粒子径 子径が 径が０ が０． ０．４ ．４～ ４～２ ～２． ２．５ ．５μ ５μｍ μｍで ｍであ であり あり、 り、屈 、屈折 屈折率 折率が 率が１ が１． １．４ ．４～ ４～１ ～１． １．７ ．７で ７であ であり あり、 り、比 、比重 比重が 重が２ が２． ２．１ ．１以 １以下 以下で 下であ である ある粒 る粒子 粒子を 子を含 を含む 含む、 む、イ 、イン インク ンクジ クジェ ジェッ ェット ットイ トイン インク ンク。',\n","       '発光性 光性ナ 性ナノ ナノ結 ノ結晶 結晶粒 晶粒子 粒子を 子を含 を含有 含有す 有する する少 る少な 少なく なくと くとも とも１ も１種 １種の 種の発 の発光 発光性 光性イ 性イン インク ンク組 ク組成 組成物 成物と 物と、 と、光 、光散 光散乱 散乱性 乱性粒 性粒子 粒子を 子を含 を含有 含有す 有する する非 る非発 非発光 発光性 光性イ 性イン インク ンク組 ク組成 組成物 成物と 物と、 と、を 、を含 を含む 含む、 む、イ 、イン インク ンク組 ク組成 組成物 成物セ 物セッ セット ット。 ト。発 。発光 発光性 光性ナ 性ナノ ナノ結 ノ結晶 結晶粒 晶粒子 粒子を 子を含 を含有 含有す 有する する少 る少な 少なく なくと くとも とも１ も１種 １種の 種の発 の発光 発光性 光性画 性画素 画素部 素部と 部と、 と、光 、光散 光散乱 散乱性 乱性粒 性粒子 粒子を 子を含 を含有 含有す 有する する非 る非発 非発光 発光性 光性画 性画素 画素部 素部と 部と、 と、を 、を備 を備え 備える える、 る、光 、光変 光変換 変換層 換層。',\n","       '少なく なくと くとも ともイ もイン インク ンクジ クジェ ジェッ ェット ットイ トイン インク ンクと クと前 と前処 前処理 処理液 理液を 液を含 を含む 含むイ むイン インク ンクジ クジェ ジェッ ェット ット記 ト記録 記録液 録液セ 液セッ セット ットで トであ であっ あって って、 て、前 、前記 前記イ 記イン インク ンクジ クジェ ジェッ ェット ットイ トイン インク ンクが クが、 が、少 、少な 少なく なくと くとも とも顔 も顔料 顔料、 料、顔 、顔料 顔料分 料分散 分散剤 散剤、 剤、水 、水溶 水溶性 溶性有 性有機 有機溶 機溶媒 溶媒及 媒及び 及び水 び水不 水不溶 不溶性 溶性樹 性樹脂 樹脂を 脂を含 を含有 含有し 有し、 し、当 、当該 当該水 該水不 水不溶 不溶性 溶性樹 性樹脂 樹脂が 脂が、 が、ポ 、ポリ ポリエ リエス エステ ステル テル骨 ル骨格 骨格、 格、ポ 、ポリ ポリオ リオレ オレフ レフィ フィン ィン骨 ン骨格 骨格又 格又は 又はポ はポリ ポリウ リウレ ウレタ レタン タン骨 ン骨格 骨格の 格のい のいず いずれ ずれか れかを かを含 を含む 含む水 む水不 水不溶 不溶性 溶性樹 性樹脂 樹脂で 脂であ であり あり、 り、前 、前記 前記前 記前処 前処理 処理液 理液が 液が、 が、少 、少な 少なく なくと くとも とも凝 も凝集 凝集剤 集剤及 剤及び 及び水 び水不 水不溶 不溶性 溶性樹 性樹脂 樹脂微 脂微粒 微粒子 粒子を 子を含 を含有 含有し 有し、 し、当 、当該 当該水 該水不 水不溶 不溶性 溶性樹 性樹脂 樹脂微 脂微粒 微粒子 粒子が 子が、 が、ポ 、ポリ ポリオ リオレ オレフ レフィ フィン ィン系 ン系樹 系樹脂 樹脂が 脂がポ がポリ ポリウ リウレ ウレタ レタン タン系 ン系樹 系樹脂 樹脂に 脂に含 に含有 含有さ 有され された れた複 た複合 複合樹 合樹脂 樹脂粒 脂粒子 粒子で 子であ である あるこ ること ことを とを特 を特徴 特徴と 徴とす とする するイ るイン インク ンクジ クジェ ジェッ ェット ット記 ト記録 記録液 録液セ 液セッ セット ット。'],\n","      dtype='<U1971')"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"M4xy1C5aE-Ki","executionInfo":{"status":"ok","timestamp":1603066346419,"user_tz":-540,"elapsed":2462,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"106b3088-d217-4822-b6aa-b5adabaa134a","colab":{"base_uri":"https://localhost:8080/","height":237}},"source":["n = 2\n","import numpy as np\n","def ngram(words, n):\n","  # n文字ずつ切り出し、1文字×nのタプル生成\n","  # ('染', '色'), ('色', '液'), ('液', 'に')\n","  ngram = list(zip(*(words[i:] for i in range(n))))\n","  # n文字の文字列リストに変換　'染色', '色液', '液に', 'によ'\n","  # リストの要素をスペースで連結して一つの文字列にする\n","  return ' '.join([''.join(j) for j in ngram])\n","\n","processed_data = np.load('data/processed_data.npy')\n","result = []\n","for text in processed_data:\n","  result.append(ngram(text, n))\n","result = np.array(result)\n","np.save('data/'+str(n)+'gram_data.npy', result)\n","result[:10]\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['第１ １の の液 液体 体を を基 基材 材表 表面 面に に付 付与 与さ され れて てな なる る第 第１ １液 液層 層を を形 形成 成す する る工 工程 程と と、 、前 前記 記第 第１ １液 液層 層が が形 形成 成さ され れた た前 前記 記基 基材 材表 表面 面に に、 、前 前記 記第 第１ １の の液 液体 体と とは は非 非相 相溶 溶で であ あり り、 、か かつ つ、 、前 前記 記第 第１ １の の液 液体 体よ より りも も比 比重 重が が大 大き きい い第 第２ ２の の液 液体 体の の液 液滴 滴を をイ イン ンク クジ ジェ ェッ ット ト法 法で で付 付与 与す する る工 工程 程と と、 、前 前記 記第 第１ １の の液 液体 体お およ よび び第 第２ ２の の液 液体 体の の一 一方 方の の液 液体 体を を選 選択 択的 的に に硬 硬化 化さ させ せる る工 工程 程と と、 、を を有 有す する る、 、パ パタ ター ーン ン形 形成 成方 方法 法。 。イ イン ンク クジ ジェ ェッ ット ト法 法に によ より り基 基材 材表 表面 面に に付 付与 与さ され れた た液 液体 体が が硬 硬化 化し して て形 形成 成さ され れた たパ パタ ター ーン ン形 形成 成物 物で であ あっ って て、 、前 前記 記液 液体 体の の硬 硬化 化物 物に によ より り形 形成 成さ され れる るパ パタ ター ーン ンが が有 有す する る前 前記 記基 基材 材表 表面 面に に接 接す する る壁 壁面 面と と、 、前 前記 記基 基材 材表 表面 面と と、 、の の間 間の の角 角度 度は は、 、４ ４５ ５° °以 以上 上で であ ある る、 、パ パタ ター ーン ン形 形成 成物 物。 。第 第１ １の の液 液体 体を を基 基材 材表 表面 面に に付 付与 与す する る第 第１ １液 液体 体付 付与 与部 部と と、 、前 前記 記第 第１ １の の液 液体 体が が付 付与 与さ され れた た前 前記 記基 基材 材表 表面 面に に、 、前 前記 記第 第１ １の の液 液体 体と とは は非 非相 相溶 溶で であ あり り、 、か かつ つ、 、前 前記 記第 第１ １の の液 液体 体よ より りも も比 比重 重が が大 大き きい い第 第２ ２の の液 液体 体の の液 液滴 滴を をイ イン ンク クジ ジェ ェッ ット ト法 法で で付 付与 与す する る第 第２ ２液 液体 体付 付与 与部 部と と、 、前 前記 記第 第１ １の の液 液体 体お およ よび び第 第２ ２の の液 液体 体の の一 一方 方の の液 液体 体を を選 選択 択的 的に に硬 硬化 化さ させ せる る選 選択 択的 的硬 硬化 化部 部と と、 、を を有 有す する る、 、パ パタ ター ーン ン形 形成 成装 装置 置。',\n","       '２種 種以 以上 上の の金 金属 属に によ よっ って て構 構成 成さ され れる る導 導電 電性 性細 細線 線に によ よっ って て構 構成 成さ され れる る、 、１ １０ ００ ００ ０ｃ ｃｍ ｍ２ ２以 以上 上の の面 面積 積に にわ わた たる る導 導電 電性 性細 細線 線パ パタ ター ーン ンの の製 製造 造方 方法 法で であ あっ って て、 、基 基材 材上 上に に第 第１ １の の金 金属 属に によ よっ って て構 構成 成さ され れた た第 第１ １の の導 導電 電性 性細 細線 線を をパ パタ ター ーニ ニン ング グし し、 、次 次い いで で、 、前 前記 記第 第１ １の の導 導電 電性 性細 細線 線に に、 、前 前記 記第 第１ １の の金 金属 属と とは は異 異な なる る金 金属 属種 種で であ ある る第 第２ ２の の金 金属 属に によ よっ って て構 構成 成さ され れた た導 導電 電性 性皮 皮膜 膜を を被 被覆 覆す する る被 被覆 覆処 処理 理を を施 施し して て、 、前 前記 記第 第１ １の の導 導電 電性 性細 細線 線と と前 前記 記導 導電 電性 性皮 皮膜 膜と とに によ よっ って て構 構成 成さ され れた た第 第２ ２の の導 導電 電性 性細 細線 線を を形 形成 成し し、 、次 次い いで で、 、前 前記 記第 第２ ２の の導 導電 電性 性細 細線 線に に、 、該 該第 第２ ２の の導 導電 電性 性細 細線 線の の線 線幅 幅の の減 減少 少速 速度 度が が０ ０． ．５ ５μ μｍ ｍ／ ／ｍ ｍｉ ｉｎ ｎ以 以下 下と とな なる るエ エッ ッチ チン ング グを を施 施し して て、 、前 前記 記第 第２ ２の の導 導電 電性 性細 細線 線を を構 構成 成す する る前 前記 記導 導電 電性 性皮 皮膜 膜の の一 一部 部が が除 除去 去さ され れた た第 第３ ３の の導 導電 電性 性細 細線 線を を形 形成 成す する るこ こと とを を特 特徴 徴と とす する る導 導電 電性 性細 細線 線パ パタ ター ーン ンの の製 製造 造方 方法 法。',\n","       '染色 色液 液に によ よる るメ メデ ディ ィア アへ への の着 着色 色度 度合 合を を調 調整 整す する る単 単独 独で では は前 前記 記メ メデ ディ ィア ア上 上で で視 視認 認困 困難 難な な染 染色 色調 調整 整剤 剤と と、 、色 色材 材と とを を含 含有 有す する る染 染色 色調 調整 整イ イン ンク クを を前 前記 記メ メデ ディ ィア アに にイ イン ンク クジ ジェ ェッ ット ト方 方式 式に によ より り塗 塗布 布す する る塗 塗布 布工 工程 程と と、 、前 前記 記染 染色 色調 調整 整イ イン ンク クが が塗 塗布 布さ され れた た前 前記 記メ メデ ディ ィア アを を前 前記 記染 染色 色液 液に に浸 浸漬 漬し して て染 染色 色す する る染 染色 色工 工程 程と と、 、を を備 備え える る、 、染 染色 色物 物の の製 製造 造方 方法 法。 。染 染色 色液 液に によ よる るメ メデ ディ ィア アへ への の着 着色 色度 度合 合を を調 調整 整す する る単 単独 独で では は前 前記 記メ メデ ディ ィア ア上 上で で視 視認 認困 困難 難な な染 染色 色調 調整 整剤 剤と と、 、前 前記 記染 染色 色液 液に によ よる る染 染色 色工 工程 程で で視 視認 認で でき きな なく くな なる るま まで で除 除去 去さ され れる る色 色材 材と と、 、を を含 含有 有す する る染 染色 色調 調整 整イ イン ンク クジ ジェ ェッ ット トイ イン ンク ク。 。染 染色 色液 液に によ よる るメ メデ ディ ィア アへ への の着 着色 色度 度合 合を を調 調整 整す する る単 単独 独で では は前 前記 記メ メデ ディ ィア ア上 上で で視 視認 認困 困難 難な な染 染色 色調 調整 整剤 剤と と、 、前 前記 記染 染色 色液 液に によ よる る染 染色 色工 工程 程で で視 視認 認可 可能 能な な程 程度 度に に残 残存 存す する る色 色材 材と と、 、を を含 含有 有す する る染 染色 色調 調整 整イ イン ンク クジ ジェ ェッ ット トイ イン ンク ク。 。染 染色 色液 液に によ よる るメ メデ ディ ィア アへ への の着 着色 色度 度合 合を を調 調整 整す する る単 単独 独で では は前 前記 記メ メデ ディ ィア ア上 上で で視 視認 認困 困難 難な な染 染色 色調 調整 整剤 剤と と、 、前 前記 記染 染色 色液 液に によ よる る染 染色 色工 工程 程で で視 視認 認可 可能 能な な程 程度 度に に残 残存 存す する る第 第１ １の の色 色材 材と と、 、を を含 含有 有す する る第 第１ １の の染 染色 色調 調整 整イ イン ンク クジ ジェ ェッ ット トイ イン ンク クと と、 、前 前記 記染 染色 色調 調整 整剤 剤と と、 、前 前記 記染 染. .. ..',\n","       '着色 色剤 剤、 、ア アラ ラビ ビア アガ ガム ム、 、炭 炭素 素数 数１ １２ ２以 以上 上、 、２ ２０ ０以 以下 下の の高 高級 級ア アル ルコ コー ール ル、 、炭 炭素 素数 数１ １以 以上 上、 、４ ４以 以下 下の の低 低級 級ア アル ルコ コー ール ル、 、お およ よび び水 水を を含 含む むイ イン ンク クジ ジェ ェッ ット トイ イン ンク ク。',\n","       '少な なく くと とも も前 前処 処理 理液 液と とイ イン ンク クと とか から らな なる るイ イン ンク クジ ジェ ェッ ット ト記 記録 録液 液セ セッ ット トで であ あっ って て、 、前 前記 記前 前処 処理 理液 液が が、 、少 少な なく くと とも も、 、ポ ポリ リエ エス ステ テル ル、 、ポ ポリ リオ オレ レフ フィ ィン ン又 又は はポ ポリ リウ ウレ レタ タン ンの の骨 骨格 格の のい いず ずれ れか かを を含 含む む水 水不 不溶 溶性 性樹 樹脂 脂微 微粒 粒子 子と と凝 凝集 集剤 剤と と水 水と とを を含 含有 有し し、 、前 前記 記イ イン ンク クが が、 、少 少な なく くと とも も、 、顔 顔料 料と とオ オキ キサ サゾ ゾリ リン ン基 基を を有 有す する る化 化合 合物 物と と水 水と とを を含 含有 有す する る、 、こ こと とを を特 特徴 徴と とす する るイ イン ンク クジ ジェ ェッ ット ト記 記録 録液 液セ セッ ット ト。',\n","       'イン ンク クジ ジェ ェッ ット ト用 用の の水 水性 性イ イン ンク クの の製 製造 造方 方法 法で であ あっ って て、 、顔 顔料 料、 、及 及び び界 界面 面活 活性 性剤 剤を を混 混合 合し して て混 混合 合物 物を を得 得る る工 工程 程と と、 、得 得ら られ れた た前 前記 記混 混合 合物 物、 、及 及び びそ その の他 他の のイ イン ンク ク成 成分 分を を混 混合 合す する る工 工程 程と と、 、を を有 有し し、 、前 前記 記顔 顔料 料が が、 、顔 顔料 料の の粒 粒子 子表 表面 面に に、 、（ （ｉ ｉ） ）ア アニ ニオ オン ン性 性基 基、 、及 及び び、 、（ （ｉ ｉｉ ｉ） ）他 他の の原 原子 子団 団と とア アニ ニオ オン ン性 性基 基と とが が結 結合 合し した た基 基、 、か から らな なる る群 群よ より り選 選択 択さ され れる る官 官能 能基 基が が結 結合 合し した た自 自己 己分 分散 散顔 顔料 料で であ ある ると とと とも もに に、 、前 前記 記官 官能 能基 基の の密 密度 度が が、 、０ ０． ．１ １０ ０μ μｍ ｍｏ ｏｌ ｌ／ ／ｍ ｍ2 2以 以上 上０ ０． ．４ ４８ ８μ μｍ ｍｏ ｏｌ ｌ／ ／ｍ ｍ2 2以 以下 下で であ あり り、 、前 前記 記界 界面 面活 活性 性剤 剤が が、 、陽 陽イ イオ オン ンと とな なり りう うる る窒 窒素 素原 原子 子が が第 第２ ２級 級ア アミ ミン ン又 又は は第 第３ ３級 級ア アミ ミン ンの の構 構造 造を を有 有す する るア アミ ミノ ノ酸 酸型 型界 界面 面活 活性 性剤 剤で であ ある るこ こと とを を特 特徴 徴と とす する る水 水性 性イ イン ンク クの の製 製造 造方 方法 法。',\n","       '水性 性媒 媒体 体と と、 、ス スク クア アリ リリ リウ ウム ム骨 骨格 格を を有 有す する る化 化合 合物 物と と樹 樹脂 脂と とを を含 含有 有す する る赤 赤外 外線 線吸 吸収 収性 性粒 粒子 子と と、 、ジ ジア アル ルキ キル ルス スル ルホ ホコ コハ ハク ク酸 酸塩 塩と と、 、赤 赤色 色ア アゾ ゾ顔 顔料 料と と、 、を を含 含む む水 水性 性イ イン ンク ク。 。水 水性 性媒 媒体 体と と、 、ス スク クア アリ リリ リウ ウム ム骨 骨格 格を を有 有す する る化 化合 合物 物と と樹 樹脂 脂と とを を含 含有 有す する る赤 赤外 外線 線吸 吸収 収性 性粒 粒子 子と と、 、ジ ジア アル ルキ キル ルス スル ルホ ホコ コハ ハク ク酸 酸塩 塩と と、 、赤 赤色 色顔 顔料 料と と、 、を を含 含み み、 、６ ６０ ０℃ ℃の の環 環境 境下 下で で１ １４ ４日 日間 間経 経過 過す する るこ こと とに によ よる る前 前記 記赤 赤外 外線 線吸 吸収 収性 性粒 粒子 子に にお おけ ける る赤 赤外 外線 線吸 吸光 光係 係数 数の の低 低下 下率 率が が５ ５％ ％以 以下 下で であ ある る水 水性 性イ イン ンク ク。',\n","       '平均 均粒 粒子 子径 径が が０ ０． ．４ ４～ ～２ ２． ．５ ５μ μｍ ｍで であ あり り、 、屈 屈折 折率 率が が１ １． ．４ ４～ ～１ １． ．７ ７で であ あり り、 、比 比重 重が が２ ２． ．１ １以 以下 下で であ ある る粒 粒子 子を を含 含む む、 、イ イン ンク クジ ジェ ェッ ット トイ イン ンク ク。',\n","       '発光 光性 性ナ ナノ ノ結 結晶 晶粒 粒子 子を を含 含有 有す する る少 少な なく くと とも も１ １種 種の の発 発光 光性 性イ イン ンク ク組 組成 成物 物と と、 、光 光散 散乱 乱性 性粒 粒子 子を を含 含有 有す する る非 非発 発光 光性 性イ イン ンク ク組 組成 成物 物と と、 、を を含 含む む、 、イ イン ンク ク組 組成 成物 物セ セッ ット ト。 。発 発光 光性 性ナ ナノ ノ結 結晶 晶粒 粒子 子を を含 含有 有す する る少 少な なく くと とも も１ １種 種の の発 発光 光性 性画 画素 素部 部と と、 、光 光散 散乱 乱性 性粒 粒子 子を を含 含有 有す する る非 非発 発光 光性 性画 画素 素部 部と と、 、を を備 備え える る、 、光 光変 変換 換層 層。',\n","       '少な なく くと とも もイ イン ンク クジ ジェ ェッ ット トイ イン ンク クと と前 前処 処理 理液 液を を含 含む むイ イン ンク クジ ジェ ェッ ット ト記 記録 録液 液セ セッ ット トで であ あっ って て、 、前 前記 記イ イン ンク クジ ジェ ェッ ット トイ イン ンク クが が、 、少 少な なく くと とも も顔 顔料 料、 、顔 顔料 料分 分散 散剤 剤、 、水 水溶 溶性 性有 有機 機溶 溶媒 媒及 及び び水 水不 不溶 溶性 性樹 樹脂 脂を を含 含有 有し し、 、当 当該 該水 水不 不溶 溶性 性樹 樹脂 脂が が、 、ポ ポリ リエ エス ステ テル ル骨 骨格 格、 、ポ ポリ リオ オレ レフ フィ ィン ン骨 骨格 格又 又は はポ ポリ リウ ウレ レタ タン ン骨 骨格 格の のい いず ずれ れか かを を含 含む む水 水不 不溶 溶性 性樹 樹脂 脂で であ あり り、 、前 前記 記前 前処 処理 理液 液が が、 、少 少な なく くと とも も凝 凝集 集剤 剤及 及び び水 水不 不溶 溶性 性樹 樹脂 脂微 微粒 粒子 子を を含 含有 有し し、 、当 当該 該水 水不 不溶 溶性 性樹 樹脂 脂微 微粒 粒子 子が が、 、ポ ポリ リオ オレ レフ フィ ィン ン系 系樹 樹脂 脂が がポ ポリ リウ ウレ レタ タン ン系 系樹 樹脂 脂に に含 含有 有さ され れた た複 複合 合樹 樹脂 脂粒 粒子 子で であ ある るこ こと とを を特 特徴 徴と とす する るイ イン ンク クジ ジェ ェッ ット ト記 記録 録液 液セ セッ ット ト。'],\n","      dtype='<U1481')"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"1dxGxmAZUFcN"},"source":["# ベクトル化\n","\n","形態素に分割されたテキストを数値化します。\n","\n","参考：[機械学習 〜 テキスト特徴量（CountVectorizer, TfidfVectorizer） 〜](https://qiita.com/fujin/items/b1a7152c2ec2b4963160)"]},{"cell_type":"markdown","metadata":{"id":"09Xl8ciUX4gI"},"source":["## Bag of Words\n","\n","scikit-leran モジュールの [Countvectrizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) を使用して、単語の出現頻度を求めます。\n","\n","参考：[【python】sklearnのCountVectorizerの使い方｜静かなる名辞](https://www.haya-programming.com/entry/2018/02/25/044525)　ほか多数\n","\n","注意：\n","\n","１）すべての文書を読み込んで一気にベクトル化する必要があります。\n","\n","２）データ量が多いので [scipy.sparse.csr_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) 形式で出力されます。"]},{"cell_type":"code","metadata":{"id":"1lk4xfdcQobv","executionInfo":{"status":"ok","timestamp":1603066648685,"user_tz":-540,"elapsed":19705,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"7082d74b-5df4-4c44-f6af-adc62df4cd68","colab":{"base_uri":"https://localhost:8080/","height":817}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","import numpy as np\n","from scipy.sparse import csr_matrix\n","from scipy.io import mmwrite, mmread\n","\n","# MeCab、sentencepiece、3-gram で分割したファイルを読み込みます。\n","files = [['MeCab', 'data/mecab_data.npy'], \n","         ['sentencepiece', 'data/sentencepiece_data.npy'], \n","         ['2-gram', 'data/2gram_data.npy'], \n","         ['3-gram', 'data/3gram_data.npy']\n","         ]\n","vectorizer = CountVectorizer(ngram_range=(1, 1), analyzer='word')\n","\n","for method, file in files:\n","  print(method+'で分割した文書をベクトル化')\n","  corpus = np.load(file, allow_pickle=True)\n","  count_vec = vectorizer.fit_transform(corpus) # csr_matrix形式\n","  savefile = file.replace('_data.npy', '_BoW_csr')\n","  mmwrite(savefile, csr_matrix(count_vec))\n","  # 再読込、表示\n","  loaddata = mmread(savefile+'.mtx').todense()\n","  print(loaddata, '\\n', loaddata.shape, '次元', '最大値', np.max(loaddata))\n","  # 形態素(0-5番目、100-105番目)表示\n","  print(vectorizer.get_feature_names()[:5], \n","        vectorizer.get_feature_names()[100:105], '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MeCabで分割した文書をベクトル化\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]] \n"," (6752, 7505) 次元 最大値 38\n","['000', '015', '10', '100', '101'] ['my', 'na', 'nf', 'nh', 'no'] \n","\n","sentencepieceで分割した文書をベクトル化\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]] \n"," (6752, 6031) 次元 最大値 38\n","['00', '000', '0000', '01', '02'] ['50', '500', '5000', '51', '52'] \n","\n","2-gramで分割した文書をベクトル化\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]] \n"," (6752, 38862) 次元 最大値 53\n","['00', '01', '02', '03', '05'] ['32', '33', '34', '35', '38'] \n","\n","3-gramで分割した文書をベクトル化\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]] \n"," (6752, 148887) 次元 最大値 38\n","['00', '000', '00k', '00の', '01'] ['1で表', '1と', '1との', '1と同', '1ない'] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FyrCW8QySJ0C"},"source":["## TF-IDF\n","scikit-leran モジュールの [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer) を使用して、単語のレア度を求めます。\n","\n","他の注意事項はCountVectrizer と同様です。"]},{"cell_type":"code","metadata":{"id":"5N9okRLQdOkP","executionInfo":{"status":"ok","timestamp":1603066716582,"user_tz":-540,"elapsed":23413,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"bda77bc6-b673-42c7-ebaf-21fcb34f298c","colab":{"base_uri":"https://localhost:8080/","height":817}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","from scipy.sparse import csr_matrix\n","from scipy.io import mmwrite, mmread\n","\n","# MeCab、sentencepiece、3-gram で分割したファイルを読み込みます。\n","files = [['MeCab', 'data/mecab_data.npy'], \n","         ['sentencepiece', 'data/sentencepiece_data.npy'], \n","         ['2-gram', 'data/2gram_data.npy'], \n","         ['3-gram', 'data/3gram_data.npy']\n","         ]\n","vectorizer = TfidfVectorizer(ngram_range=(1, 1), analyzer='word')\n","\n","for method, file in files:\n","  print(method+'で分割した文書をベクトル化')\n","  corpus = np.load(file, allow_pickle=True)\n","  tfidf_vec = vectorizer.fit_transform(corpus) # csr_matrix形式\n","  savefile = file.replace('_data.npy', '_TfIdf_csr')\n","  mmwrite(savefile, csr_matrix(tfidf_vec))\n","  # 再読込、表示\n","  loaddata = mmread(savefile+'.mtx').todense()\n","  print(loaddata, '\\n', loaddata.shape, '次元', '最大値', np.max(loaddata))\n","  # 形態素(0-5番目、100-105番目)表示\n","  print(vectorizer.get_feature_names()[:5], \n","        vectorizer.get_feature_names()[100:105], '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MeCabで分割した文書をベクトル化\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n"," (6752, 7505) 次元 最大値 0.9344405466862613\n","['000', '015', '10', '100', '101'] ['my', 'na', 'nf', 'nh', 'no'] \n","\n","sentencepieceで分割した文書をベクトル化\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n"," (6752, 6031) 次元 最大値 0.9502702649148659\n","['00', '000', '0000', '01', '02'] ['50', '500', '5000', '51', '52'] \n","\n","2-gramで分割した文書をベクトル化\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n"," (6752, 38862) 次元 最大値 0.6923048299717444\n","['00', '01', '02', '03', '05'] ['32', '33', '34', '35', '38'] \n","\n","3-gramで分割した文書をベクトル化\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n"," (6752, 148887) 次元 最大値 0.7855015753974639\n","['00', '000', '00k', '00の', '01'] ['1で表', '1と', '1との', '1と同', '1ない'] \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HtigX_MFTWZM"},"source":["CountVectrizer も TfidfVectorizer も入力文の形態素を自動抽出して計算しますが、\n","\n","vocabulary に単語のリストを与えると、与えた単語に対して計算します。"]},{"cell_type":"code","metadata":{"id":"3iy7y6lwdl5R","executionInfo":{"status":"ok","timestamp":1601718993746,"user_tz":-540,"elapsed":530,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"2b111beb-a484-477c-84b1-7bf951812488","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","from scipy.sparse import csr_matrix\n","from scipy.io import mmwrite, mmread\n","\n","# MeCab、sentencepiece、3-gram で分割したファイルを読み込みます。\n","files = [['MeCab', 'data/mecab_data.npy'], \n","         ['sentencepiece', 'data/sentencepiece_data.npy'], \n","         ['3-gram', 'data/3gram_data.npy']\n","         ]\n","vocab = ['備える', 'ノニオン', 'ペロブスカイト', 'ポリエステル', \n","         'ポリオレフィン', 'ポリカーボネート', '印刷', '原子', '重なり']\n","\n","for method, file in files:\n","  print(method+'で分割した文書をベクトル化', '\\nBoW')\n","  corpus = np.load(file, allow_pickle=True)\n","  vectorizer = CountVectorizer(ngram_range=(1, 1), analyzer='word', vocabulary=vocab)\n","  print(vectorizer.get_feature_names())\n","  count_vec = vectorizer.fit_transform(corpus) # csr_matrix形式\n","  print(count_vec.toarray()[:10], '\\n', count_vec.shape, '次元', '最大値', np.max(count_vec.toarray()), '\\nTfIdf')\n","  vectorizer = TfidfVectorizer(ngram_range=(1, 1), analyzer='word', vocabulary=vocab)\n","  tfidf_vec = vectorizer.fit_transform(corpus) # csr_matrix形式\n","  print(tfidf_vec.toarray()[:10], '\\n', tfidf_vec.shape, '次元', '最大値', np.max(tfidf_vec.toarray()), '\\n')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MeCabで分割した文書をベクトル化 \n","BoW\n","['備える', 'ノニオン', 'ペロブスカイト', 'ポリエステル', 'ポリオレフィン', 'ポリカーボネート', '印刷', '原子', '重なり']\n","[[ 1  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1  1  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  2  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1  2  0  0  0  0]\n"," [ 0  0  0  0  0  0 10  0  0]\n"," [ 0  0  0  0  0  0  0  0  0]] \n"," (50, 9) 次元 最大値 11 \n","TfIdf\n","[[1.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.67902226 0.73411768 0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         1.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [1.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.41975887 0.90763566 0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  1.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]] \n"," (50, 9) 次元 最大値 1.0 \n","\n","sentencepieceで分割した文書をベクトル化 \n","BoW\n","['備える', 'ノニオン', 'ペロブスカイト', 'ポリエステル', 'ポリオレフィン', 'ポリカーボネート', '印刷', '原子', '重なり']\n","[[ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  2  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0 10  0  1]\n"," [ 0  0  0  0  0  0  0  0  0]] \n"," (50, 9) 次元 最大値 11 \n","TfIdf\n","[[0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         1.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.98913839 0.         0.1469872 ]\n"," [0.         0.         0.         0.         0.         0.\n","  0.         0.         0.        ]] \n"," (50, 9) 次元 最大値 1.0 \n","\n","3-gramで分割した文書をベクトル化 \n","BoW\n","['備える', 'ノニオン', 'ペロブスカイト', 'ポリエステル', 'ポリオレフィン', 'ポリカーボネート', '印刷', '原子', '重なり']\n","[[1 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 0 1]\n"," [0 0 0 0 0 0 0 0 0]] \n"," (50, 9) 次元 最大値 3 \n","TfIdf\n","[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n"," (50, 9) 次元 最大値 1.0 \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EcFlsEiNYnRM"},"source":["## HashingVectrizer\n","\n","[feature hashing](https://ja.wikipedia.org/wiki/Feature_Hashing)という手法を使った埋め込み表現です。\n","\n","scikit-leran モジュールの [HashingVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer) を使用して計算します。\n","\n","単語情報は設定した(n_features)次元に分散されます。ベクトルの要素と単語とは1対1対応ではありません。"]},{"cell_type":"code","metadata":{"id":"nEcfwY73UJbG","executionInfo":{"status":"ok","timestamp":1603066811752,"user_tz":-540,"elapsed":22707,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"e72094ea-21ef-4daf-a2e9-737b37de39ab","colab":{"base_uri":"https://localhost:8080/","height":745}},"source":["from sklearn.feature_extraction.text import HashingVectorizer\n","import numpy as np\n","from scipy.sparse import csr_matrix\n","from scipy.io import mmwrite, mmread\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","\n","# MeCab、sentencepiece、3-gram で分割したファイルを読み込みます。\n","files = [['MeCab', 'data/mecab_data.npy'], \n","         ['sentencepiece', 'data/sentencepiece_data.npy'], \n","         ['2-gram', 'data/2gram_data.npy'], \n","         ['3-gram', 'data/3gram_data.npy']\n","         ]\n","n_features = [65536]\n","              #1048576]\n","              #256]\n","\n","for method, file in files:\n","  print(method+'で分割した文書をベクトル化')\n","  corpus = np.load(file, allow_pickle=True)\n","  for i in range(len(n_features)):\n","    vectorizer = HashingVectorizer(ngram_range=(1, 1), analyzer='word', n_features=n_features[i])\n","    hash_vec = vectorizer.fit_transform(corpus) # csr_matrix形式\n","    savefile = file.replace('_data.npy', '_Hash'+str(n_features[i])+'_csr')\n","    mmwrite(savefile, csr_matrix(hash_vec))\n","    # 再読込、表示\n","    loaddata = mmread(savefile+'.mtx').todense()\n","    print(loaddata, '\\n', loaddata.shape, '次元', '最大値', np.max(loaddata))\n","  print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MeCabで分割した文書をベクトル化\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n"," (6752, 65536) 次元 最大値 0.8986914687663685\n","\n","sentencepieceで分割した文書をベクトル化\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n"," (6752, 65536) 次元 最大値 0.9128709291752769\n","\n","3-gramで分割した文書をベクトル化\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n"," (6752, 65536) 次元 最大値 0.6801159602108064\n","\n","3-gramで分割した文書をベクトル化\n","[[0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," ...\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]\n"," [0. 0. 0. ... 0. 0. 0.]] \n"," (6752, 65536) 次元 最大値 0.7343236168762819\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7fBNaAVyb2iD"},"source":["## Doc2Vec\n","\n","gensim モジュールの [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html) を用いて、\n","\n","文章中の隣り合う単語の出現頻度を予測する学習を行い、\n","\n","得られたモデルに未知の文書を入力すると、学習時に設定した次元のベクトルが得られます。\n","\n","学習に用いたタグを入力すると、学習に用いた文書のベクトルが得られます。\n","\n","(参考)\n","\n","[Doc2Vecについてまとめる](https://qiita.com/g-k/items/5ea94c13281f675302ca)\n","\n","[Doc2Vecの仕組みとgensimを使った文書類似度算出チュートリアル](https://deepage.net/machine_learning/2017/01/08/doc2vec.html)\n","\n","[Word2Vecとは | 分散表現・Skip-gram法とCBOWの仕組み・ツールや活用事例まで徹底解説](https://ledge.ai/word2vec/)"]},{"cell_type":"code","metadata":{"id":"CXVQ4NivUMAT","executionInfo":{"status":"ok","timestamp":1603067463024,"user_tz":-540,"elapsed":137434,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"67130b84-ecb0-450c-b7cc-d9af13cda6dc","colab":{"base_uri":"https://localhost:8080/"}},"source":["import numpy as np\n","import pandas as pd\n","from gensim.models.doc2vec import Doc2Vec\n","from gensim.models.doc2vec import TaggedDocument\n","from scipy.sparse import csr_matrix\n","from scipy.io import mmwrite, mmread\n","import joblib\n","\n","files = [['MeCab', 'data/mecab_data.npy'], \n","         ['sentencepiece', 'data/sentencepiece_data.npy'], \n","         ['2-gram', 'data/2gram_data.npy'], \n","         ['3-gram', 'data/3gram_data.npy']\n","         ]\n","\n","for method, file in files:\n","  print(method+'で分割した文書をベクトル化')\n","  corpus = np.load(file, allow_pickle=True)\n","  training_docs = []\n","  for i in range(len(corpus)):\n","    training_docs.append(TaggedDocument(words=corpus[i],\n","                       tags=[data['公報番号(全文リンク)'][i]]))\n","  # dm=0 でDoc2Vec 学習\n","  model = Doc2Vec(documents=training_docs, vector_size=300, min_count=1, dm=0)\n","  joblib.dump(model, 'data/'+method+'_doc2vec_dm0.model', compress=3)\n","\n","  # 学習モデルに文書を入力しベクトルを得る\n","  doc_vec = []\n","  for i in range(len(data)):\n","    doc_vec.append(model.infer_vector(training_docs[i].tags))\n","  savefile = 'data/'+method+'_doc2vec_dm0_csr'\n","  mmwrite(savefile, csr_matrix(np.array(doc_vec)))\n","  # 再読込、表示\n","  loaddata = mmread(savefile+'.mtx').todense()\n","  print(loaddata, '\\n', loaddata.shape, '次元', '最大値', np.max(loaddata), '\\n')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MeCabで分割した文書をベクトル化\n","[[ 1.4443173e-03  8.3994446e-04 -9.4415143e-04 ...  1.8944054e-04\n","  -4.1765813e-04  1.2399777e-03]\n"," [ 1.1112873e-04  7.2459027e-04 -7.0364395e-04 ...  6.7487767e-04\n","  -1.0529784e-03  1.2783859e-03]\n"," [ 1.4923571e-03  7.1707985e-04 -2.9602324e-04 ... -2.6343833e-04\n","   6.0850475e-04 -8.7404816e-04]\n"," ...\n"," [ 1.0234175e-03 -6.9845311e-04  8.8316134e-05 ...  7.5546751e-04\n","  -1.4929551e-03 -1.3608179e-03]\n"," [-1.0456373e-03 -2.6351208e-04 -7.3164358e-04 ...  1.3867704e-03\n","   3.5324338e-04  1.5639717e-03]\n"," [ 1.5616795e-03 -5.6039623e-04 -1.1962391e-03 ... -1.4969831e-03\n","  -9.1569714e-04  8.4922009e-04]] \n"," (6752, 300) 次元 最大値 0.0016666665 \n","\n","sentencepieceで分割した文書をベクトル化\n","[[ 1.4443173e-03  8.3994446e-04 -9.4415143e-04 ...  1.8944054e-04\n","  -4.1765813e-04  1.2399777e-03]\n"," [ 1.1112873e-04  7.2459027e-04 -7.0364395e-04 ...  6.7487767e-04\n","  -1.0529784e-03  1.2783859e-03]\n"," [ 1.4923571e-03  7.1707985e-04 -2.9602324e-04 ... -2.6343833e-04\n","   6.0850475e-04 -8.7404816e-04]\n"," ...\n"," [ 1.0234175e-03 -6.9845311e-04  8.8316134e-05 ...  7.5546751e-04\n","  -1.4929551e-03 -1.3608179e-03]\n"," [-1.0456373e-03 -2.6351208e-04 -7.3164358e-04 ...  1.3867704e-03\n","   3.5324338e-04  1.5639717e-03]\n"," [ 1.5616795e-03 -5.6039623e-04 -1.1962391e-03 ... -1.4969831e-03\n","  -9.1569714e-04  8.4922009e-04]] \n"," (6752, 300) 次元 最大値 0.0016666665 \n","\n","2-gramで分割した文書をベクトル化\n","[[ 1.4443173e-03  8.3994446e-04 -9.4415143e-04 ...  1.8944054e-04\n","  -4.1765813e-04  1.2399777e-03]\n"," [ 1.1112873e-04  7.2459027e-04 -7.0364395e-04 ...  6.7487767e-04\n","  -1.0529784e-03  1.2783859e-03]\n"," [ 1.4923571e-03  7.1707985e-04 -2.9602324e-04 ... -2.6343833e-04\n","   6.0850475e-04 -8.7404816e-04]\n"," ...\n"," [ 1.0234175e-03 -6.9845311e-04  8.8316134e-05 ...  7.5546751e-04\n","  -1.4929551e-03 -1.3608179e-03]\n"," [-1.0456373e-03 -2.6351208e-04 -7.3164358e-04 ...  1.3867704e-03\n","   3.5324338e-04  1.5639717e-03]\n"," [ 1.5616795e-03 -5.6039623e-04 -1.1962391e-03 ... -1.4969831e-03\n","  -9.1569714e-04  8.4922009e-04]] \n"," (6752, 300) 次元 最大値 0.0016666665 \n","\n","3-gramで分割した文書をベクトル化\n","[[ 1.4443173e-03  8.3994446e-04 -9.4415143e-04 ...  1.8944054e-04\n","  -4.1765813e-04  1.2399777e-03]\n"," [ 1.1112873e-04  7.2459027e-04 -7.0364395e-04 ...  6.7487767e-04\n","  -1.0529784e-03  1.2783859e-03]\n"," [ 1.4923571e-03  7.1707985e-04 -2.9602324e-04 ... -2.6343833e-04\n","   6.0850475e-04 -8.7404816e-04]\n"," ...\n"," [ 1.0234175e-03 -6.9845311e-04  8.8316134e-05 ...  7.5546751e-04\n","  -1.4929551e-03 -1.3608179e-03]\n"," [-1.0456373e-03 -2.6351208e-04 -7.3164358e-04 ...  1.3867704e-03\n","   3.5324338e-04  1.5639717e-03]\n"," [ 1.5616795e-03 -5.6039623e-04 -1.1962391e-03 ... -1.4969831e-03\n","  -9.1569714e-04  8.4922009e-04]] \n"," (6752, 300) 次元 最大値 0.0016666665 \n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dFX_5ubQBT-T"},"source":["## ELMo\n","\n","双方向LSTMを用いて学習させた言語モデルで、文脈を考慮した単語埋め込み表現が得られます。[実装](https://pypi.org/project/elmoformanylangs/)\n","\n","（参考）\n","\n","[大規模日本語ビジネスニュースコーパスを学習したELMo（MeCab利用）モデルの紹介](https://qiita.com/mkt3/items/9577b63900109ff91665)\n","\n","[大規模日本語ビジネスニュースコーパスを学習したELMo（MeCab利用）モデルの利用方法と精度比較検証](https://qiita.com/kaeru_nantoka/items/bca53a2daea2b29c9b39)"]},{"cell_type":"code","metadata":{"id":"ZE0sz9Pd5g1C","executionInfo":{"status":"ok","timestamp":1603067662663,"user_tz":-540,"elapsed":19167,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"4eca8fca-787d-41b9-d742-51b6390b66b1","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# 必要なライブラリをインストールします。\n","%cd '/content/drive/My Drive/'\n","!pip install overrides\n","!git clone https://github.com/HIT-SCIR/ELMoForManyLangs.git\n","!sudo python 'ELMoForManyLangs/setup.py' install\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from ELMoForManyLangs.elmoformanylangs import Embedder\n","from overrides import overrides\n","from IPython.display import clear_output\n","from scipy.sparse import csr_matrix\n","from scipy.io import mmwrite, mmread"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","Collecting overrides\n","  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n","Building wheels for collected packages: overrides\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10174 sha256=7b0156bfbac49e7fb47529042f4654b15398d7f2ea2d44606a0eb53c93f6162e\n","  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n","Successfully built overrides\n","Installing collected packages: overrides\n","Successfully installed overrides-3.1.0\n","fatal: destination path 'ELMoForManyLangs' already exists and is not an empty directory.\n","running install\n","running bdist_egg\n","running egg_info\n","writing elmoformanylangs.egg-info/PKG-INFO\n","writing dependency_links to elmoformanylangs.egg-info/dependency_links.txt\n","writing requirements to elmoformanylangs.egg-info/requires.txt\n","writing top-level names to elmoformanylangs.egg-info/top_level.txt\n","reading manifest file 'elmoformanylangs.egg-info/SOURCES.txt'\n","writing manifest file 'elmoformanylangs.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n","\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying elmoformanylangs.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying elmoformanylangs.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying elmoformanylangs.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying elmoformanylangs.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying elmoformanylangs.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","creating 'dist/elmoformanylangs-0.0.2-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing elmoformanylangs-0.0.2-py3.6.egg\n","Copying elmoformanylangs-0.0.2-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding elmoformanylangs 0.0.2 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/elmoformanylangs-0.0.2-py3.6.egg\n","Processing dependencies for elmoformanylangs==0.0.2\n","Searching for overrides==3.1.0\n","Best match: overrides 3.1.0\n","Adding overrides 3.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.18.5\n","Best match: numpy 1.18.5\n","Adding numpy 1.18.5 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.6 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for h5py==2.10.0\n","Best match: h5py 2.10.0\n","Adding h5py 2.10.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for torch==1.6.0+cu101\n","Best match: torch 1.6.0+cu101\n","Adding torch 1.6.0+cu101 to easy-install.pth file\n","Installing convert-caffe2-to-onnx script to /usr/local/bin\n","Installing convert-onnx-to-caffe2 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for future==0.16.0\n","Best match: future 0.16.0\n","Adding future 0.16.0 to easy-install.pth file\n","Installing futurize script to /usr/local/bin\n","Installing pasteurize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for elmoformanylangs==0.0.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I2JgQAB6SLNH"},"source":["（作業）\n","\n","https://drive.google.com/drive/u/1/folders/1sau1I10rFeAn8BDk8eZDL5qaEjTlNghp\n","\n","こちらから　単語単位埋め込みモデル　と　文字単位・単語単位埋め込みモデル　とをダウンロードし、マイドライブにアップロードします。"]},{"cell_type":"code","metadata":{"id":"l_I-bpvRCgSZ","executionInfo":{"status":"ok","timestamp":1603069558076,"user_tz":-540,"elapsed":566676,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"524e2594-a457-437b-8586-d45282524021","colab":{"base_uri":"https://localhost:8080/","height":854}},"source":["# ELMo\n","\n","def serial_mode(txt_batch):\n","  data = []\n","  for k in range(len(txt_batch)):\n","    torch.cuda.empty_cache()\n","    data.append(char_e.sents2elmo([txt_batch[k]], output_layer=output_layer))\n","  return data\n","\n","word_model_path = './単語単位埋め込みモデル'\n","char_model_path = './文字単位・単語単位埋め込みモデル'\n","\n","# 文字単位・単語単位埋め込みモデルを読み込み\n","char_e = Embedder(model_dir=char_model_path, batch_size=64)\n","output_layer=-1 # モデルの最終段の出力を得る\n","\n","corpus = np.load('data/mecab_data.npy', allow_pickle=True)\n","\n","texts = []\n","new_array = []\n","n_batch = 25\n","print('\\nコーパス整理中')\n","for i in range(len(corpus)):\n","  texts.append(corpus[i].split(' '))\n","\n","for i in range(len(corpus)//n_batch):\n","  if i%30 == 0:\n","    clear_output()\n","  print('\\rELMo変換中\\t', \n","        str(n_batch*i)+'-'+str(n_batch*(i+1))+'/'+str(len(corpus)), end='\\t')\n","  try:\n","    data = char_e.sents2elmo(texts[n_batch*i:n_batch*(i+1)], output_layer=output_layer)\n","    torch.cuda.empty_cache()\n","    # 可変長ベクトルの平均をとり固定長ベクトルにする\n","    for j in range(len(data)):\n","      new_array.append(np.average(data[j], axis=0).reshape(1,-1))\n","    torch.cuda.empty_cache()\n","  except:\n","    # n_batch数の処理でメモリオーバーフローを起こすとき1文書ずつ処理する\n","    print('serial mode')\n","    data = serial_mode(texts[n_batch*i:n_batch*i+1])\n","    for j in range(len(data)):\n","      new_array.append(np.average(data[j][0], axis=0).reshape(1,-1))\n","      torch.cuda.empty_cache()\n","    print('\\rELMo変換中\\t', \n","        str(n_batch*i)+'-'+str(len(corpus))+'/'+str(len(corpus)), end='\\t')\n","data = serial_mode(texts[n_batch*(i+1):])\n","for j in range(len(data)):\n","  new_array.append(np.average(data[j][0], axis=0).reshape(1,-1))\n","\n","new_array = np.vstack(new_array)\n","mmwrite('data/mecab_ELMo_csr', csr_matrix(new_array))\n","print('実行結果', new_array.shape, '\\n', new_array)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-10-19 01:04:44,936 INFO: 1 batches, avg len: 175.2\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6000-6025/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:04:46,760 INFO: 1 batches, avg len: 213.3\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6025-6050/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:04:48,625 INFO: 1 batches, avg len: 189.4\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6050-6075/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:04:50,457 INFO: 1 batches, avg len: 213.4\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6075-6100/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:04:52,446 INFO: 1 batches, avg len: 198.6\n"],"name":"stderr"},{"output_type":"stream","text":["ELMo変換中\t 6125-6150/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:04:54,473 INFO: 1 batches, avg len: 244.9\n","2020-10-19 01:04:56,599 INFO: 1 batches, avg len: 214.2\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6150-6175/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:04:58,505 INFO: 1 batches, avg len: 203.9\n"],"name":"stderr"},{"output_type":"stream","text":["ELMo変換中\t 6200-6225/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:00,454 INFO: 1 batches, avg len: 234.6\n","2020-10-19 01:05:02,412 INFO: 1 batches, avg len: 201.6\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6225-6250/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:04,280 INFO: 1 batches, avg len: 193.3\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6250-6275/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:06,198 INFO: 1 batches, avg len: 221.4\n"],"name":"stderr"},{"output_type":"stream","text":["ELMo変換中\t 6300-6325/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:08,315 INFO: 1 batches, avg len: 250.2\n","2020-10-19 01:05:10,390 INFO: 1 batches, avg len: 216.4\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6325-6350/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:12,381 INFO: 1 batches, avg len: 181.4\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6350-6375/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:14,269 INFO: 1 batches, avg len: 199.1\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6375-6400/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:16,086 INFO: 1 batches, avg len: 159.6\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6400-6425/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:17,980 INFO: 1 batches, avg len: 215.6\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6425-6450/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:20,052 INFO: 1 batches, avg len: 186.5\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6450-6475/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:21,947 INFO: 1 batches, avg len: 211.0\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6475-6500/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:23,936 INFO: 1 batches, avg len: 197.2\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6500-6525/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:25,823 INFO: 1 batches, avg len: 187.4\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6525-6550/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:27,710 INFO: 1 batches, avg len: 207.4\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6550-6575/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:29,657 INFO: 1 batches, avg len: 205.0\n"],"name":"stderr"},{"output_type":"stream","text":["ELMo変換中\t 6600-6625/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:31,674 INFO: 1 batches, avg len: 239.8\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6625-6650/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:33,833 INFO: 1 batches, avg len: 217.8\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6650-6675/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:35,797 INFO: 1 batches, avg len: 242.9\n","2020-10-19 01:05:37,902 INFO: 1 batches, avg len: 214.2\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6675-6700/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:39,866 INFO: 1 batches, avg len: 217.9\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6700-6725/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:41,933 INFO: 1 batches, avg len: 179.8\n"],"name":"stderr"},{"output_type":"stream","text":["\rELMo変換中\t 6725-6750/6752\t"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:05:43,697 INFO: 1 batches, avg len: 191.0\n","2020-10-19 01:05:44,194 INFO: 1 batches, avg len: 55.0\n"],"name":"stderr"},{"output_type":"stream","text":["実行結果 (6752, 1024) \n"," [[ 0.07609484  0.13494179 -0.1271863  ...  0.35290182  0.30815312\n","  -0.1912412 ]\n"," [-0.11880717  0.14558306 -0.10437959 ...  0.4845544   0.20008522\n","  -0.7493846 ]\n"," [-0.1683051   0.100697    0.17939211 ...  0.5429394   0.40682924\n","  -0.01956601]\n"," ...\n"," [-0.18878338  0.10764265 -0.23103067 ...  0.4900653  -0.1243621\n","  -0.45817044]\n"," [-0.13619576  0.18513697  0.21140532 ...  0.5173607   0.14656053\n","  -0.21277009]\n"," [-0.0048144   0.09562767  0.41113737 ...  0.769303    0.00904824\n","  -0.6708213 ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wSaPaVo6KfkV"},"source":["## sentence-transformers日本語版\n","\n","https://github.com/sonoisa/sentence-transformers\n","\n","（参考）\n","\n","[はじめての自然言語処理｜第9回 Sentence BERT による類似文章検索の検証](https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/part9.html)"]},{"cell_type":"code","metadata":{"id":"jf-tXVQxAH4D","executionInfo":{"status":"ok","timestamp":1603069569538,"user_tz":-540,"elapsed":5381,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"5a7bb4ab-7cb4-4c4a-8457-eef51dbf5a61","colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["! pip install mecab-python3==0.996.5"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting mecab-python3==0.996.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/49/b55a839a77189042960bf96490640c44816073f917d489acbc5d79fa5cc3/mecab_python3-0.996.5-cp36-cp36m-manylinux2010_x86_64.whl (17.1MB)\n","\u001b[K     |████████████████████████████████| 17.1MB 202kB/s \n","\u001b[?25hInstalling collected packages: mecab-python3\n","Successfully installed mecab-python3-0.996.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W731JqPZKeuK","executionInfo":{"status":"ok","timestamp":1603069577968,"user_tz":-540,"elapsed":11526,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"48bef842-b6df-435a-9631-8999e9208046","colab":{"base_uri":"https://localhost:8080/","height":855}},"source":["%cd '/content/drive/My Drive/'\n","!git clone https://github.com/sonoisa/sentence-transformers\n","!cd sentence-transformers; pip install -r requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'sentence-transformers' already exists and is not an empty directory.\n","Collecting transformers==2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n","\u001b[K     |████████████████████████████████| 450kB 4.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.41.1)\n","Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.6.0+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.18.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.22.2.post1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (1.4.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n","Requirement already satisfied: mecab-python3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.996.5)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/08/f1ff665147a5d75b871bbe5ba76916f6490419c52a33e588385c4b69281b/boto3-1.15.18-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 12.5MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 10.3MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (2.23.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (0.1.91)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.1->-r requirements.txt (line 3)) (0.16.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->-r requirements.txt (line 7)) (1.15.0)\n","Collecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting botocore<1.19.0,>=1.18.18\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/72/984ac8f33b5c8df5ff63f323a8724f65b4d0f8956968b942b77d35d3a1ef/botocore-1.18.18-py2.py3-none-any.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 29.2MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 1)) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (2020.6.20)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.19.0,>=1.18.18->boto3->transformers==2.3.0->-r requirements.txt (line 1)) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=b675deefbdeb3605493636ab48d57ef045e08458fbc9bbdc8a5120d350c7483d\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, sacremoses, transformers\n","Successfully installed boto3-1.15.18 botocore-1.18.18 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 transformers-2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mj334FvTLOg5","executionInfo":{"status":"ok","timestamp":1603069628086,"user_tz":-540,"elapsed":56353,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"43ee5c75-a93d-44ac-aaad-4a4f9ddedd42","colab":{"base_uri":"https://localhost:8080/","height":565}},"source":["!wget -O sonobe-datasets-sentence-transformers-model.tar \"https://www.floydhub.com/api/v1/resources/JLTtbaaK5dprnxoJtUbBbi?content=true&download=true&rename=sonobe-datasets-sentence-transformers-model-2\"\n","!tar -xvf sonobe-datasets-sentence-transformers-model.tar\n","%cd '/content/drive/My Drive/sentence-transformers/'\n","from sentence_transformers import SentenceTransformer\n","%cd '/content/drive/My Drive/'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-10-19 01:06:24--  https://www.floydhub.com/api/v1/resources/JLTtbaaK5dprnxoJtUbBbi?content=true&download=true&rename=sonobe-datasets-sentence-transformers-model-2\n","Resolving www.floydhub.com (www.floydhub.com)... 104.26.1.30, 104.26.0.30, 172.67.72.144, ...\n","Connecting to www.floydhub.com (www.floydhub.com)|104.26.1.30|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [application/tar]\n","Saving to: ‘sonobe-datasets-sentence-transformers-model.tar’\n","\n","sonobe-datasets-sen     [                <=> ] 422.28M  22.9MB/s    in 20s     \n","\n","2020-10-19 01:06:44 (21.5 MB/s) - ‘sonobe-datasets-sentence-transformers-model.tar’ saved [442788352]\n","\n","./\n","./training_bert_japanese/\n","./training_bert_japanese/0_BERTJapanese/\n","./training_bert_japanese/0_BERTJapanese/added_tokens.json\n","./training_bert_japanese/0_BERTJapanese/config.json\n","./training_bert_japanese/0_BERTJapanese/pytorch_model.bin\n","./training_bert_japanese/0_BERTJapanese/sentence_bert_config.json\n","./training_bert_japanese/0_BERTJapanese/special_tokens_map.json\n","./training_bert_japanese/0_BERTJapanese/tokenizer_config.json\n","./training_bert_japanese/0_BERTJapanese/vocab.txt\n","./training_bert_japanese/1_Pooling/\n","./training_bert_japanese/1_Pooling/config.json\n","./training_bert_japanese/config.json\n","./training_bert_japanese/modules.json\n","/content/drive/My Drive/sentence-transformers\n"],"name":"stdout"},{"output_type":"stream","text":["2020-10-19 01:06:50,559 INFO: PyTorch version 1.6.0+cu101 available.\n","2020-10-19 01:06:56,667 INFO: TensorFlow version 2.3.0 available.\n"],"name":"stderr"},{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KAuRL6VPOZzz","executionInfo":{"status":"ok","timestamp":1603069642280,"user_tz":-540,"elapsed":60600,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"1e767024-f7ba-4c3d-ad1f-96dca504e74f","colab":{"base_uri":"https://localhost:8080/","height":855}},"source":["%tensorflow_version 2.x\n","import numpy as np\n","model_path = '/content/drive/My Drive/training_bert_japanese'\n","model = SentenceTransformer(model_path, show_progress_bar=False)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-10-19 01:07:07,770 INFO: Load pretrained SentenceTransformer: /content/drive/My Drive/training_bert_japanese\n","2020-10-19 01:07:07,772 INFO: Load SentenceTransformer from folder: /content/drive/My Drive/training_bert_japanese\n","2020-10-19 01:07:15,260 INFO: loading configuration file /content/drive/My Drive/training_bert_japanese/0_BERTJapanese/config.json\n","2020-10-19 01:07:15,262 INFO: Model config {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 32000\n","}\n","\n","2020-10-19 01:07:15,269 INFO: loading weights file /content/drive/My Drive/training_bert_japanese/0_BERTJapanese/pytorch_model.bin\n","2020-10-19 01:07:18,036 INFO: Model name '/content/drive/My Drive/training_bert_japanese/0_BERTJapanese' not found in model shortcut name list (bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking). Assuming '/content/drive/My Drive/training_bert_japanese/0_BERTJapanese' is a path or url to a directory containing tokenizer files.\n","2020-10-19 01:07:18,038 INFO: loading file /content/drive/My Drive/training_bert_japanese/0_BERTJapanese/vocab.txt\n","2020-10-19 01:07:18,041 INFO: loading file /content/drive/My Drive/training_bert_japanese/0_BERTJapanese/added_tokens.json\n","2020-10-19 01:07:18,043 INFO: loading file /content/drive/My Drive/training_bert_japanese/0_BERTJapanese/special_tokens_map.json\n","2020-10-19 01:07:18,044 INFO: loading file /content/drive/My Drive/training_bert_japanese/0_BERTJapanese/tokenizer_config.json\n","2020-10-19 01:07:18,087 INFO: Use pytorch device: cuda\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ejBp9vVKh-Z5","executionInfo":{"status":"ok","timestamp":1603069900726,"user_tz":-540,"elapsed":84459,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"6479e9b4-0272-4306-a0dd-a27a8a568e79","colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["# document vector\n","import joblib\n","import pandas as pd\n","import numpy as np\n","from scipy.sparse import csr_matrix\n","from scipy.io import mmwrite, mmread\n","\n","corpus = np.load('data/mecab_data.npy', allow_pickle=True)\n","\n","vectors = model.encode(corpus)\n","vectors = np.vstack(vectors)\n","mmwrite('data/mecab_STtransf_csr', csr_matrix(vectors))\n","# 再読込、表示\n","loaddata = mmread('data/mecab_STtransf_csr.mtx').todense()\n","print(loaddata, '\\n', loaddata.shape, '次元', '最大値', np.max(loaddata))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[ 0.30867311  0.72003454 -1.0142187  ... -0.14144777  0.12558933\n","  -1.9725475 ]\n"," [ 0.13991801  1.4396574  -0.9894231  ... -0.31704736  0.26261249\n","  -1.7517378 ]\n"," [ 0.30623767  0.91992551 -0.36928141 ... -0.45889604 -0.18640393\n","  -1.1709334 ]\n"," ...\n"," [-0.00736655  0.31887358 -0.94143999 ...  0.3203817  -0.06085746\n","  -1.1184773 ]\n"," [ 0.90899813 -0.76965106 -0.40118608 ... -0.40824756 -0.54954857\n","  -0.34403381]\n"," [ 0.37465972 -0.33253226 -1.408565   ... -0.07329539 -0.50081831\n","  -1.7956736 ]] \n"," (6752, 768) 次元 最大値 4.1483793\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cl1MghTaoS5u"},"source":["## ラベルエンコード、one-hot ベクトル\n","\n","Tensorflow.Kerasモジュールのテキスト処理クラスである[Tokenizer](tf.keras.preprocessing.text.Tokenizer)に文書を与えることによって、\n","\n","単語IDの列からなる文書ベクトルが得られます。\n","\n","このとき、sequenceで各文書の長さをそろえますが、短い文書の後ろに 0 を付ける（zero padding）のが主流です。\n","\n","長い文書に揃えず、適当な長さで区切って、余った単語を切り捨てる方法もあります。\n","\n","参考：[Keras Documentation](https://keras.io/ja/preprocessing/text/)\n","\n","また、[np_utilsクラス](https://keras.io/ja/utils/np_utils/)の to_categorical API に数値nを入力すると、\n","\n","n番目が1で残りが0のベクトル（one-hotベクトル）が得られます。\n","\n","参考：[Keras Documentation](https://keras.io/ja/)"]},{"cell_type":"code","metadata":{"id":"rkxVvDcmlva3","executionInfo":{"status":"ok","timestamp":1601719035969,"user_tz":-540,"elapsed":2278,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"326b31f6-ccee-4fca-c248-ddf11d88070a","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# ラベルエンコード\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing import sequence\n","\n","files = [['MeCab', 'data/mecab_data.npy'], \n","         ['sentencepiece', 'data/sentencepiece_data.npy'], \n","         ['3-gram', 'data/3gram_data.npy']\n","]\n","\n","for method, file in files:\n","  print(method+'で分割した文書をベクトル化')\n","  corpus = np.load(file, allow_pickle=True)\n","  # 文字列をID列に変換\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(corpus)\n","  list_tokenized = tokenizer.texts_to_sequences(corpus)\n","  # ID列の長さを揃える\n","  list_sequence = sequence.pad_sequences(list_tokenized, maxlen=None, dtype='int32', \n","                                        padding='post', value=0.0)\n","  list_tokenized = np.array(list_sequence)\n","  print(list_tokenized, '\\n', list_tokenized.shape, '次元', '最大値', np.max(list_tokenized), '\\n')\n","  # ID列の長さを50で打ち切る\n","  list_sequence = sequence.pad_sequences(list_tokenized, maxlen=50, dtype='int32', \n","                                        padding='post', value=0.0)\n","  list_tokenized = np.array(list_sequence)\n","  print(list_tokenized, '\\n', list_tokenized.shape, '次元', '最大値', np.max(list_tokenized), '\\n')  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["MeCabで分割した文書をベクトル化\n","[[ 59  92   5 ...   0   0   0]\n"," [155  55   1 ...   0   0   0]\n"," [ 43  40 202 ...   0   0   0]\n"," ...\n"," [  6 133   3 ...   0   0   0]\n"," [103 132 107 ...   0   0   0]\n"," [342 343  48 ...   0   0   0]] \n"," (50, 307) 次元 最大値 796 \n","\n","[[ 55   7   1 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]\n"," ...\n"," [133   3 168 ...   0   0   0]\n"," [  4 198 559 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]] \n"," (50, 50) 次元 最大値 791 \n","\n","sentencepieceで分割した文書をベクトル化\n","[[ 27  49  42 ...   0   0   0]\n"," [ 27  63  89 ...   0   0   0]\n"," [ 27  37   3 ...   0   0   0]\n"," ...\n"," [ 27   4  42 ...   0   0   0]\n"," [ 27  92 137 ...   0   0   0]\n"," [ 27 383 384 ...   0   0   0]] \n"," (50, 281) 次元 最大値 1000 \n","\n","[[  8  49 133 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]\n"," ...\n"," [ 34  10   4 ...   0   0   0]\n"," [  1 128   9 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]] \n"," (50, 50) 次元 最大値 992 \n","\n","3-gramで分割した文書をベクトル化\n","[[ 256  257  304 ...    0    0    0]\n"," [2719 2720 2721 ...    0    0    0]\n"," [  22   25   26 ...    0    0    0]\n"," ...\n"," [   1  488  489 ...    0    0    0]\n"," [ 247  248  145 ...    0    0    0]\n"," [ 940  941  942 ...    0    0    0]] \n"," (50, 482) 次元 最大値 5513 \n","\n","[[161   1 125 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]\n"," ...\n"," [ 36  37  38 ...   0   0   0]\n"," [ 29 387  50 ...   0   0   0]\n"," [  0   0   0 ...   0   0   0]] \n"," (50, 50) 次元 最大値 5430 \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M0dVnDPer1hu","executionInfo":{"status":"ok","timestamp":1601719037668,"user_tz":-540,"elapsed":551,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"caaea7b4-0d65-435f-a3c0-f729f975faa1","colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["# one-hotベクトル(1)\n","# Tensorflowに取り込まれる前のKerasのutilityにあるnp_utilsを用いる方法\n","\n","from keras.utils import np_utils\n","\n","index_data = [0, 1, 0, 2, 0, 1, 0, 2]\n","np_utils.to_categorical(index_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"f3V0S3ljrtLk","executionInfo":{"status":"ok","timestamp":1601719038879,"user_tz":-540,"elapsed":605,"user":{"displayName":"西尾潤","photoUrl":"","userId":"08290973370176560667"}},"outputId":"0180a7a7-943b-4f35-8da6-08dc5c0c3a07","colab":{"base_uri":"https://localhost:8080/","height":217}},"source":["# one-hotベクトル(2)\n","# 単位行列を生成するNumPyのeye関数で単位行列を生成し、数値をかける方法\n","\n","import numpy as np\n","\n","index_data = [0, 1, 0, 2, 0, 1, 0, 2]\n","print(np.eye(max(index_data)+1)) # 3×3単位行列\n","np.eye(max(index_data)+1)[index_data]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.],\n","       [1., 0., 0.],\n","       [0., 1., 0.],\n","       [1., 0., 0.],\n","       [0., 0., 1.]])"]},"metadata":{"tags":[]},"execution_count":18}]}]}